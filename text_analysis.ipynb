{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksandra\\AppData\\Roaming\\Python\\Python36\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# импорты\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "from string import punctuation\n",
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "import csv\n",
    "import gensim\n",
    "\n",
    "import pymystem3\n",
    "m = pymystem3.Mystem() #для использования лемматизации\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack(data):\n",
    "    input = open(data, 'rb')\n",
    "    obj = pickle.load(input)\n",
    "    input.close()\n",
    "    return obj\n",
    "\n",
    "# загружаем частоты лем униграмм\n",
    "unigrams = unpack('1stemgrams.data')\n",
    "# обрезали по частоте 20, а еще убрали пробел из начала слов\n",
    "unigrams = {w[1:]:f for w,f in unigrams.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# читает из файла, убирает двойные пробелы и ручные переносы, последний \\n\n",
    "def reading(file):\n",
    "    f = open('texts\\\\{}.txt'.format(file), 'r', encoding='utf-8')\n",
    "    text = f.read()\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace('-\\n', '')\n",
    "    if text[-1] == '\\n': # убираем последний \\n, если такой есть \n",
    "        text = text[:-1]\n",
    "    f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimummaker(): #ф-ция превращения текстового файла с минимумом в питоновский список. Запаковка списка\n",
    "    with open('min.txt', encoding='utf-8') as file:\n",
    "        lemtokens = [morph.parse(i)[0].normal_form for i in re.findall('\\w+', file.read().lower())] #делаем список лемм слов\n",
    "        minimum = list(set(lemtokens)) #убираем повторы\n",
    "        output = open('minimum.pkl', 'wb')\n",
    "        pickle.dump(minimum, output, 2)\n",
    "        output.close()\n",
    "\n",
    "def loadminimum(): #распаковка cписка с минимумом. Возвращает неупорядоченный список\n",
    "    input = open('minimum.pkl', 'rb')\n",
    "    minimum = pickle.load(input)\n",
    "    input.close()\n",
    "    return minimum\n",
    "\n",
    "#minimummaker()\n",
    "minimum = loadminimum()\n",
    "#print(minimum[-50:]) #проверка работы\n",
    "#print(len(minimum)) #2549 слов в списке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# загрузка модели\n",
    "def model_loading(file):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(file, binary=False)\n",
    "    model.init_sims(replace=True)\n",
    "    print('Done!') \n",
    "    return model\n",
    "\n",
    "model = model_loading('news_upos_cbow_600_2_2018.vec') #на загрузку тратится минут 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загрузка словаря ASIS\n",
    "with open('syns.data', 'rb') as f:\n",
    "     asis = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Таблица конверсии в UPoS из тэгов Mystem\n",
    "# словарь, переводящий теги mystem в universal теги моделей\n",
    "mystem_tags = {'A' : 'ADJ',\n",
    "       'ADV' : 'ADV',\n",
    "       'ADVPRO' : 'ADV',\n",
    "       'ANUM' : 'ADJ',\n",
    "       'APRO' : 'DET',\n",
    "       'COM' : 'ADJ',\n",
    "       'CONJ' : 'SCONJ',\n",
    "       'INTJ' : 'INTJ',\n",
    "       'NONLEX' : 'X',\n",
    "       'NUM' : 'NUM',\n",
    "       'PART' : 'PART',\n",
    "       'PR' : 'ADP',\n",
    "       'S' : 'NOUN',\n",
    "       'SPRO' : 'PRON',\n",
    "       'UNKN' : 'X',\n",
    "       'V' : 'VERB',\n",
    "       'X' : 'X',\n",
    "      'PROPN' : 'PROPN'} #последних 2 тегов в майстеме нет, но они задаются в классе для слов в соответсвующими пометами\n",
    "\n",
    "# словарь, переводящий теги пайморфи в universal теги моделей\n",
    "pymorphy_tags = {'ADJF':'ADJ',\n",
    "    'ADJS' : 'ADJ',\n",
    "    'ADVB' : 'ADV',\n",
    "    'COMP' : 'ADV',\n",
    "    'GRND' : 'VERB',\n",
    "    'INFN' : 'VERB',\n",
    "    'NOUN' : 'NOUN',\n",
    "    'PRED' : 'ADV',\n",
    "    'PRTF' : 'ADJ',\n",
    "    'PRTS' : 'VERB',\n",
    "    'VERB' : 'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Пример вывода атрибутов объектов класса \\ntoken.num, token.text, token.lem, token.pos, token.complexity, token.is_complex(threshold, use_min):\\n\\n223 Кукушкин _NAMED_ENTITY_ S -19.06687873346149 False\\n224   _SPACE_ None -19.06687873346149 False\\n225 является являться V -7.502177090710664 False\\n226   _SPACE_ None -19.06687873346149 False\\n227 должником должник S -11.184186527172464 True\\n228   _SPACE_ None -19.06687873346149 False\\n229 банка банк S -9.300701131889967 False\\n230 .  _PUNKTUATION_ None -19.06687873346149 False\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Token():\n",
    "    def __init__(self, w):\n",
    "        \n",
    "        self.num = None # номер в тексте\n",
    "        self.complexity = None # сложность слова\n",
    "        \n",
    "        # три варианта инициализации: \n",
    "        ## из анализа текста, \n",
    "        ## из уже имеющегося объекта (для дочернего класса ComplexWord) \n",
    "        ## из строки\n",
    "        \n",
    "        if isinstance(w, dict): # если получили результат работы mystem\n",
    "            \n",
    "            self.text = w['text']  # сам токен\n",
    "            self.len = len(w['text']) # его длина\n",
    "            \n",
    "            # определяет, сделан ли анализ и, соответственно, рассматривать ли как слово, требующее упрощения\n",
    "            gram = w.get('analysis')\n",
    "            if gram:\n",
    "                self.lexem = gram[0]['lex']  # лемма\n",
    "                \n",
    "                if not self.named_entity(gram[0]):  # именованная сущность или нет\n",
    "                    self.pos = self.pos_tag(gram[0]['gr'])  # часть речи\n",
    "                else:\n",
    "                    self.pos = 'PROPN' # universal tag for named entity - у майстема таких нет\n",
    "                \n",
    "                    \n",
    "            elif any(p in w['text'] for p in punctuation+'–«»'): # если это знак пунктуации (может быть с пробелом!)\n",
    "                self.lexem = '_PUNKTUATION_'\n",
    "                self.pos = None\n",
    "            \n",
    "            elif not re.findall('\\S',w['text']): # если это только пробельные символы\n",
    "                self.lexem = '_SPACE_'\n",
    "                self.pos = None\n",
    "                \n",
    "            # остальное - неизвестная и ненужная ерунда?\n",
    "            else:\n",
    "                self.lexem = '_UNK_'\n",
    "                self.pos = 'X' # universal tag for unknown\n",
    "            \n",
    "            \n",
    "        elif isinstance(w, Token): # для определения объектов дочернего класса ComplexWord\n",
    "            self.text = w.text\n",
    "            self.num = w.num\n",
    "            self.lexem = w.lexem \n",
    "            self.len = w.len\n",
    "            self.pos = w.pos\n",
    "            self.complexity = w.complexity\n",
    "            \n",
    "        \n",
    "        elif isinstance(w, str): # если хотим как класс токен определить строку, полученную из словаря или модели\n",
    "            self.text = w\n",
    "            self.pos = None\n",
    "            self.lexem = w\n",
    "            self.len = len(w)\n",
    "            self.num = None\n",
    "            self.complexity = None\n",
    "            \n",
    "        \n",
    "    # вытаскивает часть речи из разбора майстем\n",
    "    def pos_tag(self,gram):\n",
    "        if ',' in gram:\n",
    "            gram = gram.split(',')[0]\n",
    "        if '=' in gram:\n",
    "            gram = gram.split('=')[0]\n",
    "        return gram\n",
    "        \n",
    "    # определяет по тегам, является ли именованной сущностью\n",
    "    def named_entity(self,gram):\n",
    "        markers = {'сокр': ' - сокращение', 'фам': ' - фамилия', 'имя': ' - имя собственное', 'гео': ' - название места', }\n",
    "        if any(m in gram['gr'] for m in markers.keys()):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def complexity_params(self, param = 'freq'):\n",
    "        # если по частотности\n",
    "        if param == 'freq':\n",
    "            self.complexity = unigrams.get(self.lem, 0)\n",
    "            \n",
    "        # если по коэффициенту информативности. Отрицательное значение. Чем он меньше, тем сложнее\n",
    "        elif param == 'inf':\n",
    "            self.complexity = math.log((unigrams.get(self.lexem, 0)+1)/(sum(f for f in unigrams.values())+1))\n",
    "        \n",
    "    \n",
    "    def is_complex(self, threshold = '600', use_min = False, len_threshold = 1000):\n",
    "        exceptions = ['_PUNKTUATION_', '_SPACE_', '_UNK_']\n",
    "        # проверка, что это слово и что его нужно рассматривать как сложное (не нарицательное)\n",
    "        if not any(exception in self.lexem for exception in exceptions) and self.pos not in ['PROPN']:\n",
    "            \n",
    "            # если показатель сложности - вхождение в минимум\n",
    "            if use_min:\n",
    "                if self.lexem not in minimum:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "\n",
    "            # если показатель сложности - пороговое значение сложности\n",
    "            # также может использоваться длина. По умолчанию слишком большое - 1000 (т.е. этот параметр не учитывается)\n",
    "            else:\n",
    "                if self.complexity < threshold or self.len > len_threshold:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def convert_universal(self):\n",
    "        if self.pos in mystem_tags:\n",
    "            self.pos = mystem_tags[self.pos]\n",
    "        else:\n",
    "            self.pos = 'X' # Х - universal тег для неизвестных слов\n",
    "        \n",
    "'''Пример вывода атрибутов объектов класса \n",
    "token.num, token.text, token.lem, token.pos, token.complexity, token.is_complex(threshold, use_min):\n",
    "\n",
    "223 Кукушкин _NAMED_ENTITY_ S -19.06687873346149 False\n",
    "224   _SPACE_ None -19.06687873346149 False\n",
    "225 является являться V -7.502177090710664 False\n",
    "226   _SPACE_ None -19.06687873346149 False\n",
    "227 должником должник S -11.184186527172464 True\n",
    "228   _SPACE_ None -19.06687873346149 False\n",
    "229 банка банк S -9.300701131889967 False\n",
    "230 .  _PUNKTUATION_ None -19.06687873346149 False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''# вытаскивает часть речи из разбора майстем\n",
    "def pos(gram):\n",
    "    if ',' in gram:\n",
    "        gram = gram.split(',')[0]\n",
    "    if '=' in gram:\n",
    "        gram = gram.split('=')[0]\n",
    "    return gram\n",
    "'''\n",
    "\n",
    "#анализ текста \n",
    "def text_structuring(text, param, threshold, use_min):\n",
    "    # анализирует текст \n",
    "    analysis = m.analyze(text)\n",
    "    tokens = []\n",
    "    for i, w in enumerate(analysis): # состаляем список объектов Tokens\n",
    "        token = Token(w)\n",
    "        token.num = i # добавляем токену в атрибуты его номер в тексте\n",
    "        token.complexity_params(param) # переопределяем сложность на основе выбранного параметра\n",
    "        token.convert_universal() # превращаем POS в universal формат\n",
    "        print(token.num, token.text, token.lexem, token.pos, token.complexity, token.is_complex(threshold, use_min))\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ПАРАМЕТРЫ анализа слов\n",
    "complexity_type = 'inf'\n",
    "global_threshold = -8.5\n",
    "use_min=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 В в ADP -3.486155131943022 False\n",
      "1   _SPACE_ X -19.06687873346149 False\n",
      "2 Астраханской астраханский ADJ -11.87544940342511 True\n",
      "3   _SPACE_ X -19.06687873346149 False\n",
      "4 области область NOUN -8.188095962474803 False\n",
      "5   _SPACE_ X -19.06687873346149 False\n",
      "6 ветерану ветеран NOUN -10.97250028848853 True\n",
      "7   _SPACE_ X -19.06687873346149 False\n",
      "8 ВОВ вов PROPN -14.907995650101817 False\n",
      "9   _SPACE_ X -19.06687873346149 False\n",
      "10 вернули вернуть VERB -9.947667294896409 False\n",
      "11   _SPACE_ X -19.06687873346149 False\n",
      "12 похищенные похищать VERB -11.006654493020532 True\n",
      "13   _SPACE_ X -19.06687873346149 False\n",
      "14 медали медаль NOUN -10.586972126831268 True\n",
      "15 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "16 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "17 В в ADP -3.486155131943022 False\n",
      "18   _SPACE_ X -19.06687873346149 False\n",
      "19 Астраханской астраханский ADJ -11.87544940342511 True\n",
      "20   _SPACE_ X -19.06687873346149 False\n",
      "21 области область NOUN -8.188095962474803 False\n",
      "22   _SPACE_ X -19.06687873346149 False\n",
      "23 ветерану ветеран NOUN -10.97250028848853 True\n",
      "24   _SPACE_ X -19.06687873346149 False\n",
      "25 Великой великий ADJ -7.707722354468047 False\n",
      "26   _SPACE_ X -19.06687873346149 False\n",
      "27 Отечественной отечественный ADJ -9.66113606515282 True\n",
      "28   _SPACE_ X -19.06687873346149 False\n",
      "29 войны война NOUN -7.816461543327748 False\n",
      "30   _SPACE_ X -19.06687873346149 False\n",
      "31 вернули вернуть VERB -9.947667294896409 False\n",
      "32   _SPACE_ X -19.06687873346149 False\n",
      "33 украденные украсть VERB -10.412361351182033 True\n",
      "34   _SPACE_ X -19.06687873346149 False\n",
      "35 у у ADP -5.476072944878379 False\n",
      "36   _SPACE_ X -19.06687873346149 False\n",
      "37 него он PRON -4.13305326453326 False\n",
      "38   _SPACE_ X -19.06687873346149 False\n",
      "39 наградные наградные NOUN -19.06687873346149 True\n",
      "40   _SPACE_ X -19.06687873346149 False\n",
      "41 медали медаль NOUN -10.586972126831268 True\n",
      "42 .  _PUNKTUATION_ X -19.06687873346149 False\n",
      "43 Об об ADP -7.262754885511919 True\n",
      "44   _SPACE_ X -19.06687873346149 False\n",
      "45 этом это PRON -4.869477438777567 False\n",
      "46   _SPACE_ X -19.06687873346149 False\n",
      "47 сообщает сообщать VERB -8.634205145827439 False\n",
      "48   _SPACE_ X -19.06687873346149 False\n",
      "49 портал портал NOUN -12.693558943884478 True\n",
      "50  \" _PUNKTUATION_ X -19.06687873346149 False\n",
      "51 Утро утро NOUN -7.969832414948298 False\n",
      "52 . _PUNKTUATION_ X -19.06687873346149 False\n",
      "53 ру _UNK_ X -19.06687873346149 False\n",
      "54 \"  _PUNKTUATION_ X -19.06687873346149 False\n",
      "55 со со ADP -6.752575195748552 True\n",
      "56   _SPACE_ X -19.06687873346149 False\n",
      "57 ссылкой ссылка NOUN -10.338452641756877 True\n",
      "58   _SPACE_ X -19.06687873346149 False\n",
      "59 на на ADP -4.174175661002731 False\n",
      "60   _SPACE_ X -19.06687873346149 False\n",
      "61 пресс-службу пресс-служба NOUN -12.117981511148177 True\n",
      "62   _SPACE_ X -19.06687873346149 False\n",
      "63 регионального региональный ADJ -10.073575594367755 True\n",
      "64   _SPACE_ X -19.06687873346149 False\n",
      "65 МВД мвд PROPN -10.974639326737279 False\n",
      "66 . _PUNKTUATION_ X -19.06687873346149 False\n",
      "67 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "68 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "69 —  _UNK_ X -19.06687873346149 False\n",
      "70 Оперативники оперативник NOUN -12.197864282795782 True\n",
      "71   _SPACE_ X -19.06687873346149 False\n",
      "72 задержали задерживать VERB -9.988813400795125 True\n",
      "73   _SPACE_ X -19.06687873346149 False\n",
      "74 подозреваемую подозревать VERB -10.114143966354618 True\n",
      "75   _SPACE_ X -19.06687873346149 False\n",
      "76 в в ADP -3.486155131943022 False\n",
      "77   _SPACE_ X -19.06687873346149 False\n",
      "78 совершении совершение NOUN -10.903792357878274 True\n",
      "79   _SPACE_ X -19.06687873346149 False\n",
      "80 преступления преступление NOUN -9.447944818702611 True\n",
      "81 .  _PUNKTUATION_ X -19.06687873346149 False\n",
      "82 Ею она PRON -4.9255734554932324 False\n",
      "83   _SPACE_ X -19.06687873346149 False\n",
      "84 оказалась оказываться VERB -7.507967031654563 False\n",
      "85   _SPACE_ X -19.06687873346149 False\n",
      "86 61 _UNK_ X -19.06687873346149 False\n",
      "87 - _PUNKTUATION_ X -19.06687873346149 False\n",
      "88 летняя летний ADJ -9.444031438588096 False\n",
      "89   _SPACE_ X -19.06687873346149 False\n",
      "90 женщина женщина NOUN -7.588223853768708 False\n",
      "91 ,  _PUNKTUATION_ X -19.06687873346149 False\n",
      "92 которая который DET -5.3951392436881935 False\n",
      "93   _SPACE_ X -19.06687873346149 False\n",
      "94 помогала помогать VERB -8.13600640154562 False\n",
      "95   _SPACE_ X -19.06687873346149 False\n",
      "96 ветерану ветеран NOUN -10.97250028848853 True\n",
      "97   _SPACE_ X -19.06687873346149 False\n",
      "98 по по ADP -5.1820044394556914 False\n",
      "99   _SPACE_ X -19.06687873346149 False\n",
      "100 дому дом NOUN -7.446301380034336 False\n",
      "101 , —  _PUNKTUATION_ X -19.06687873346149 False\n",
      "102 сообщили сообщать VERB -8.634205145827439 False\n",
      "103   _SPACE_ X -19.06687873346149 False\n",
      "104 правоохранители правоохранитель NOUN -14.589541918983283 True\n",
      "105 . _PUNKTUATION_ X -19.06687873346149 False\n",
      "106 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "107 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "108 Женщина женщина NOUN -7.588223853768708 False\n",
      "109   _SPACE_ X -19.06687873346149 False\n",
      "110 объяснила объяснять VERB -8.424936082660874 False\n",
      "111   _SPACE_ X -19.06687873346149 False\n",
      "112 свои свой DET -5.485855828512082 False\n",
      "113   _SPACE_ X -19.06687873346149 False\n",
      "114 действия действие NOUN -8.051517218274066 False\n",
      "115   _SPACE_ X -19.06687873346149 False\n",
      "116 тем то PRON -5.111209789976896 False\n",
      "117 ,  _PUNKTUATION_ X -19.06687873346149 False\n",
      "118 что что SCONJ -4.319951223892165 False\n",
      "119   _SPACE_ X -19.06687873346149 False\n",
      "120 между между ADP -7.221517739852308 False\n",
      "121   _SPACE_ X -19.06687873346149 False\n",
      "122 ней она PRON -4.9255734554932324 False\n",
      "123   _SPACE_ X -19.06687873346149 False\n",
      "124 и и SCONJ -3.24763166905925 False\n",
      "125   _SPACE_ X -19.06687873346149 False\n",
      "126 ветераном ветеран NOUN -10.97250028848853 True\n",
      "127   _SPACE_ X -19.06687873346149 False\n",
      "128 возник возникать VERB -8.524383446466064 True\n",
      "129   _SPACE_ X -19.06687873346149 False\n",
      "130 конфликт конфликт NOUN -10.099502040248822 True\n",
      "131 ,  _PUNKTUATION_ X -19.06687873346149 False\n",
      "132 после после ADP -6.881269033189423 False\n",
      "133   _SPACE_ X -19.06687873346149 False\n",
      "134 чего что PRON -4.319951223892165 False\n",
      "135   _SPACE_ X -19.06687873346149 False\n",
      "136 она она PRON -4.9255734554932324 False\n",
      "137   _SPACE_ X -19.06687873346149 False\n",
      "138 забрала забирать VERB -9.812521476068532 True\n",
      "139   _SPACE_ X -19.06687873346149 False\n",
      "140 сковородку сковородка NOUN -12.13736196269784 True\n",
      "141   _SPACE_ X -19.06687873346149 False\n",
      "142 и и SCONJ -3.24763166905925 False\n",
      "143   _SPACE_ X -19.06687873346149 False\n",
      "144 награды награда NOUN -10.257165192953222 False\n",
      "145 ,  _PUNKTUATION_ X -19.06687873346149 False\n",
      "146 которые который DET -5.3951392436881935 False\n",
      "147   _SPACE_ X -19.06687873346149 False\n",
      "148 впоследствии впоследствии ADV -9.601353654626301 True\n",
      "149   _SPACE_ X -19.06687873346149 False\n",
      "150 выбросила выбрасывать VERB -10.114532190235263 True\n",
      "151   _SPACE_ X -19.06687873346149 False\n",
      "152 в в ADP -3.486155131943022 False\n",
      "153   _SPACE_ X -19.06687873346149 False\n",
      "154 урну урна NOUN -12.071112577156638 True\n",
      "155 . _PUNKTUATION_ X -19.06687873346149 False\n",
      "156 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "157 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "158 Полиция полиция NOUN -9.704847848244874 False\n",
      "159   _SPACE_ X -19.06687873346149 False\n",
      "160 обследовала обследовать VERB -11.754325235358891 True\n",
      "161   _SPACE_ X -19.06687873346149 False\n",
      "162 территорию территория NOUN -9.167750669702814 False\n",
      "163   _SPACE_ X -19.06687873346149 False\n",
      "164 городской городской ADJ -9.074556467224872 False\n",
      "165   _SPACE_ X -19.06687873346149 False\n",
      "166 свалки свалка NOUN -11.606963967220384 True\n",
      "167   _SPACE_ X -19.06687873346149 False\n",
      "168 и и SCONJ -3.24763166905925 False\n",
      "169   _SPACE_ X -19.06687873346149 False\n",
      "170 нашла находить VERB -7.451604282941571 False\n",
      "171   _SPACE_ X -19.06687873346149 False\n",
      "172 часть часть NOUN -7.373550217519937 False\n",
      "173   _SPACE_ X -19.06687873346149 False\n",
      "174 похищенных похищать VERB -11.006654493020532 True\n",
      "175   _SPACE_ X -19.06687873346149 False\n",
      "176 наград награда NOUN -10.257165192953222 False\n",
      "177   _SPACE_ X -19.06687873346149 False\n",
      "178 среди среди ADP -8.093024057697555 False\n",
      "179   _SPACE_ X -19.06687873346149 False\n",
      "180 твёрдых твердый ADJ -9.473318862324462 True\n",
      "181   _SPACE_ X -19.06687873346149 False\n",
      "182 бытовых бытовой ADJ -10.493116190557357 False\n",
      "183   _SPACE_ X -19.06687873346149 False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 отходов отходы NOUN -12.430932177774844 True\n",
      "185 .  _PUNKTUATION_ X -19.06687873346149 False\n",
      "186 В в ADP -3.486155131943022 False\n",
      "187   _SPACE_ X -19.06687873346149 False\n",
      "188 отношении отношение NOUN -7.621322458862115 False\n",
      "189   _SPACE_ X -19.06687873346149 False\n",
      "190 задержанной задерживать VERB -9.988813400795125 True\n",
      "191   _SPACE_ X -19.06687873346149 False\n",
      "192 возбуждено возбуждать VERB -9.872871016106204 True\n",
      "193   _SPACE_ X -19.06687873346149 False\n",
      "194 уголовное уголовный ADJ -9.858339983431934 True\n",
      "195   _SPACE_ X -19.06687873346149 False\n",
      "196 дело дело NOUN -6.454827778200301 False\n",
      "197 . _PUNKTUATION_ X -19.06687873346149 False\n",
      "198 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "199 \n",
      " _SPACE_ X -19.06687873346149 False\n",
      "200 Напомним напоминать VERB -8.79944275302013 False\n",
      "201 ,  _PUNKTUATION_ X -19.06687873346149 False\n",
      "202 ранее ранее ADV -9.877966308898927 True\n",
      "203   _SPACE_ X -19.06687873346149 False\n",
      "204 Лайф лайф PROPN -14.956004869288178 False\n",
      "205   _SPACE_ X -19.06687873346149 False\n",
      "206 сообщал сообщать VERB -8.634205145827439 False\n",
      "207 ,  _PUNKTUATION_ X -19.06687873346149 False\n",
      "208 что что SCONJ -4.319951223892165 False\n",
      "209   _SPACE_ X -19.06687873346149 False\n",
      "210 у у ADP -5.476072944878379 False\n",
      "211   _SPACE_ X -19.06687873346149 False\n",
      "212 93 _UNK_ X -19.06687873346149 False\n",
      "213 - _PUNKTUATION_ X -19.06687873346149 False\n",
      "214 летнего летний ADJ -9.444031438588096 False\n",
      "215   _SPACE_ X -19.06687873346149 False\n",
      "216 Василия василий PROPN -9.180639074334914 False\n",
      "217   _SPACE_ X -19.06687873346149 False\n",
      "218 Легонького легонький ADJ -13.029007813539351 True\n",
      "219   _SPACE_ X -19.06687873346149 False\n",
      "220 украли украсть VERB -10.412361351182033 True\n",
      "221   _SPACE_ X -19.06687873346149 False\n",
      "222 из из ADP -5.430146815838169 False\n",
      "223   _SPACE_ X -19.06687873346149 False\n",
      "224 квартиры квартира NOUN -8.362735792650131 False\n",
      "225   _SPACE_ X -19.06687873346149 False\n",
      "226 10 _UNK_ X -19.06687873346149 False\n",
      "227   _SPACE_ X -19.06687873346149 False\n",
      "228 наградных наградные NOUN -19.06687873346149 True\n",
      "229   _SPACE_ X -19.06687873346149 False\n",
      "230 медалей медаль NOUN -10.586972126831268 True\n",
      "231  \" _PUNKTUATION_ X -19.06687873346149 False\n",
      "232 За за ADP -5.532348753209741 False\n",
      "233   _SPACE_ X -19.06687873346149 False\n",
      "234 отвагу отвага NOUN -11.840669723360818 True\n",
      "235 \", \" _PUNKTUATION_ X -19.06687873346149 False\n",
      "236 За за ADP -5.532348753209741 False\n",
      "237   _SPACE_ X -19.06687873346149 False\n",
      "238 взятие взятие NOUN -11.427236445603477 True\n",
      "239   _SPACE_ X -19.06687873346149 False\n",
      "240 Берлина берлин PROPN -10.198324692930289 False\n",
      "241 \"  _PUNKTUATION_ X -19.06687873346149 False\n",
      "242 и и SCONJ -3.24763166905925 False\n",
      "243  \" _PUNKTUATION_ X -19.06687873346149 False\n",
      "244 За за ADP -5.532348753209741 False\n",
      "245   _SPACE_ X -19.06687873346149 False\n",
      "246 взятие взятие NOUN -11.427236445603477 True\n",
      "247   _SPACE_ X -19.06687873346149 False\n",
      "248 Кёнигсберга кенигсберг PROPN -12.822711832797753 False\n",
      "249 \" _PUNKTUATION_ X -19.06687873346149 False\n",
      "250 . _PUNKTUATION_ X -19.06687873346149 False\n",
      "251 \n",
      " _SPACE_ X -19.06687873346149 False\n"
     ]
    }
   ],
   "source": [
    "text = reading('news3')\n",
    "tokens = text_structuring(text, complexity_type, global_threshold, use_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Substitution(Token):\n",
    "    def __init__(self, w):\n",
    "        super().__init__(w)\n",
    "        self.similarity = None\n",
    "        self.fitness = None\n",
    "    \n",
    "    # для слов из словаря и тезауруса: определяем тег пайморфи, переводим в формат universal - так быстрее, чем майстемом\n",
    "    def tagging(self, w):\n",
    "        tag = morph.parse(w)[0].tag.POS\n",
    "        if tag in pymorphy_tags:\n",
    "            return pymorphy_tags[tag]\n",
    "        else:\n",
    "            return 'X' # Х - universal тег для неизвестных слов\n",
    "\n",
    "    # в случае, когда Substitution получено не через модель, и его близость неизвестна\n",
    "    def measuse_similarity(self, target):\n",
    "        #print(self.lexem, target.lexem, self.pos, target.pos)\n",
    "        subst_query = str(self.lexem+'_'+self.pos)\n",
    "        target_query = str(target.lexem+'_'+target.pos)\n",
    "        if subst_query in model and target_query in model:\n",
    "            self.similarity = model.similarity(subst_query, target_query)\n",
    "        # может понадобиться return self\n",
    "    \n",
    "    # приписываем атрибуты словам, взятым из словаря или тезауруса\n",
    "    def setting_atr(self, target):\n",
    "        self.pos = self.tagging(self.lexem)\n",
    "        self.complexity_params(complexity_type)\n",
    "        self.measuse_similarity(target)\n",
    "        \n",
    "    def language_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Complex_word(Token):\n",
    "    def __init__(self, w):\n",
    "        super().__init__(w)\n",
    "        self.substituts = None\n",
    "        self.place = None\n",
    "        self.context = None\n",
    "        \n",
    "    # список замен, в зависимости от выбранной базы\n",
    "    def search_substituts(self, base_type='model'):\n",
    "        \n",
    "        # поиск по модели\n",
    "        def model_search(lexem, pos):\n",
    "            query = str(lexem+'_'+pos)\n",
    "            #print(query)\n",
    "            if query in model:\n",
    "                # формируем список квазисинонимов той же части речи\n",
    "                # при этом превращаем их в объекты соответствующего класса\n",
    "                syn_tokens = []\n",
    "                for syn, sim in model.most_similar(positive=[query]):\n",
    "                    syn_text = syn[:syn.find('_')] # текст до части речи\n",
    "                    \n",
    "                    syn_tok = Substitution(syn_text) # из текстовой строки инициализируем объект класса\n",
    "                    syn_tok.pos = syn[syn_tok.len+1:] # часть речи\n",
    "                    \n",
    "                    syn_tok.complexity_params(complexity_type) # сложность по функции в зависимости от выбранного параметра\n",
    "                    \n",
    "                    syn_tok.similarity = sim # а близость по параметру модели\n",
    "                    \n",
    "                    syn_tokens.append(syn_tok)\n",
    "                    \n",
    "                return syn_tokens\n",
    "            else:\n",
    "                return [] \n",
    "\n",
    "        # поиск по YARN\n",
    "        def yarn_search(target, filepath = 'yarn-synsets1.csv'):\n",
    "            with open(filepath, \"r\", newline=\"\") as file: # постепенный просмотр файла с синсетами (множествами синонимов)\n",
    "                reader = csv.DictReader(file, delimiter=';')\n",
    "                lst = []\n",
    "                for i,row in enumerate(reader):\n",
    "                    cur_line = row['words'].split(';') # считываем колонку с синсетами\n",
    "                    if len(cur_line)>1:\n",
    "                        if target.lexem in cur_line:\n",
    "                            del(reader)\n",
    "                            for c in cur_line:\n",
    "                                if ' ' not in c and c!=target.lexem: # формируем список однословных синонимов\n",
    "                                    sub_tok = Substitution(c)\n",
    "                                    \n",
    "                                    sub_tok.setting_atr(target)\n",
    "                                    \n",
    "                                    lst.append(sub_tok) \n",
    "                            #TODO: выделить неоднословные в отдельный класс и поискать их частотность по n-граммам?\n",
    "                            break\n",
    "                #print(lst)\n",
    "                return lst \n",
    "        \n",
    "        #поиск по ASIS\n",
    "        def asis_search(target):\n",
    "            if target.lexem in asis:\n",
    "                lst = []\n",
    "                for s in asis[target.lexem]:\n",
    "                    if ' ' not in s: # формируем список однословных синонимов\n",
    "                        sub_tok = Substitution(s)\n",
    "                        sub_tok.setting_atr(target)\n",
    "                        lst.append(sub_tok)\n",
    "                return lst\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        \n",
    "        if base_type == 'model':\n",
    "            self.substituts = model_search(self.lexem, self.pos)\n",
    "            \n",
    "        if base_type == 'yarn':\n",
    "            self.substituts = yarn_search(self)\n",
    "        \n",
    "        if base_type == 'asis':\n",
    "            self.substituts = asis_search(self)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def make_window(self, tokens, window = 10):\n",
    "        context = [self]\n",
    "        left_ind = self.num-1\n",
    "        right_ind = self.num+1\n",
    "        ind = 0\n",
    "        # добавляем по одному слову слева и/или справа, пока не наберется window + само слово\n",
    "        while len(context)<window+1:\n",
    "            while left_ind >= 0:\n",
    "                left_w = tokens[left_ind]\n",
    "                left_ind-=1\n",
    "                # проверка, что это слово\n",
    "                if any(exception in left_w.lexem for exception in ['_PUNKTUATION_', '_SPACE_', '_UNK_']):\n",
    "                    continue\n",
    "                else:\n",
    "                    context[:0] = [left_w] #вставляем слово слева от цепочки\n",
    "                    ind+=1 # индекс слова сдвигается\n",
    "                    break\n",
    "\n",
    "            while right_ind < len(tokens):\n",
    "                right_w = tokens[right_ind]\n",
    "                right_ind+=1\n",
    "                # проверка, что это слово и что его нужно рассматривать как сложное (не нарицательное)\n",
    "                if any(exception in right_w.lexem for exception in ['_PUNKTUATION_', '_SPACE_', '_UNK_']):\n",
    "                    continue\n",
    "                else:\n",
    "                    context.append(right_w) # справа от цепочки\n",
    "                    break\n",
    "        self.place = ind\n",
    "        self.context = context\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ветеран X yarn : пенсионер NOUN -11.268766104631702 None\n",
      "ветеран X yarn : старикашка NOUN -13.024245899779109 None\n",
      "ветеран X yarn : старик NOUN -8.345441216450578 None\n",
      "ветеран X yarn : дед NOUN -9.259296537812432 None\n",
      "похищать X yarn : прикарманивать VERB -14.697430880994467 None\n",
      "похищать X yarn : присваивать VERB -11.139915188598511 None\n",
      "похищать X yarn : обкрадывать VERB -12.261156180044503 None\n",
      "похищать X yarn : красть VERB -11.887570763957456 None\n",
      "похищать X yarn : обворовывать VERB -13.383298966122808 None\n",
      "похищать X yarn : таскать VERB -10.896410155130816 None\n",
      "похищать X yarn : воровать VERB -11.085145446769603 None\n",
      "медаль X yarn : орден NOUN -10.085071410083955 None\n",
      "ветеран X yarn : пенсионер NOUN -11.268766104631702 None\n",
      "ветеран X yarn : старикашка NOUN -13.024245899779109 None\n",
      "ветеран X yarn : старик NOUN -8.345441216450578 None\n",
      "ветеран X yarn : дед NOUN -9.259296537812432 None\n",
      "отечественный X yarn : исконный ADJ -11.975968911381505 None\n",
      "отечественный X yarn : коренной ADJ -10.819396729175796 None\n",
      "отечественный X yarn : домотканный ADJ -19.06687873346149 None\n",
      "отечественный X yarn : здешний ADJ -10.117643419086635 None\n",
      "отечественный X yarn : доморощенный ADJ -12.742519771080179 None\n",
      "отечественный X yarn : тамошний ADJ -11.174800312213371 None\n",
      "отечественный X yarn : местный ADJ -8.792828124826462 None\n",
      "отечественный X yarn : природный ADJ -9.77293277763051 None\n",
      "отечественный X yarn : родной ADJ -9.113982160667819 None\n",
      "отечественный X yarn : туземный ADJ -12.428310944294969 None\n",
      "отечественный X yarn : домоделанный ADJ -19.06687873346149 None\n",
      "украсть X yarn : похитить VERB -19.06687873346149 None\n",
      "украсть X yarn : стянуть VERB -19.06687873346149 None\n",
      "украсть X yarn : стащить VERB -17.45744082102739 None\n",
      "украсть X yarn : выкрасть VERB -19.06687873346149 None\n",
      "украсть X yarn : красть VERB -11.887570763957456 None\n",
      "украсть X yarn : своровать VERB -14.600970614806906 None\n",
      "медаль X yarn : орден NOUN -10.085071410083955 None\n",
      "об X yarn : относительно X -9.566035271846824 None\n",
      "об X yarn : насчет X -9.630917880296204 None\n",
      "об X yarn : касательно X -12.210416748866903 None\n",
      "об X yarn : о X -5.629415606889456 None\n",
      "портал X yarn : вход NOUN -9.731845917527988 None\n",
      "портал X yarn : врата NOUN -11.742388754112957 None\n",
      "портал X yarn : дверь NOUN -7.711707098541537 None\n",
      "со X yarn : изо X -10.14903199093431 None\n",
      "со X yarn : зело ADV -12.568596583985055 None\n",
      "со X yarn : из X -5.430146815838169 None\n",
      "со X yarn : з X -10.780357359780254 None\n",
      "со X yarn : с X -4.45008658009755 None\n",
      "ссылка X yarn : изгнание NOUN -11.570226295293207 None\n",
      "ссылка X yarn : экспатриация NOUN -19.06687873346149 None\n",
      "ссылка X yarn : депортация NOUN -13.586239810119498 None\n",
      "региональный X yarn : областной ADJ -10.250470233779797 None\n",
      "региональный X yarn : местный ADJ -8.792828124826462 None\n",
      "задерживать X yarn : удерживать VERB -9.74428167913964 None\n",
      "задерживать X yarn : улавливать VERB -10.677746212112769 None\n",
      "подозревать X yarn : предполагать VERB -9.086244971748707 None\n",
      "подозревать X yarn : думать VERB -7.108101460589846 None\n",
      "совершение X yarn : реализация NOUN -9.928894023677447 None\n",
      "совершение X yarn : исполнение NOUN -9.393307616527 None\n",
      "совершение X yarn : осуществление NOUN -10.108467264231269 None\n",
      "совершение X yarn : воплощение NOUN -10.935936431229612 None\n",
      "совершение X yarn : создание NOUN -8.909252965508928 None\n",
      "совершение X yarn : претворение NOUN -13.410886922641637 None\n",
      "преступление X yarn : злодейство NOUN -12.191646646184912 None\n",
      "преступление X yarn : злодеяние NOUN -12.101798387860082 None\n",
      "ветеран X yarn : пенсионер NOUN -11.268766104631702 None\n",
      "ветеран X yarn : старикашка NOUN -13.024245899779109 None\n",
      "ветеран X yarn : старик NOUN -8.345441216450578 None\n",
      "ветеран X yarn : дед NOUN -9.259296537812432 None\n",
      "ветеран X yarn : пенсионер NOUN -11.268766104631702 None\n",
      "ветеран X yarn : старикашка NOUN -13.024245899779109 None\n",
      "ветеран X yarn : старик NOUN -8.345441216450578 None\n",
      "ветеран X yarn : дед NOUN -9.259296537812432 None\n",
      "возникать X yarn : наступать VERB -8.994323739809822 None\n",
      "возникать X yarn : подниматься VERB -8.366785291997186 None\n",
      "возникать X yarn : наставать VERB -10.454557196953674 None\n",
      "возникать X yarn : появляться VERB -8.062597938932536 None\n",
      "возникать X yarn : начинаться VERB -8.153027397811316 None\n",
      "возникать X yarn : рождаться VERB -9.118656849585191 None\n",
      "возникать X yarn : зарождаться VERB -11.45800810427023 None\n",
      "возникать X yarn : происходить VERB -7.775560500548489 None\n",
      "конфликт X yarn : разногласие NOUN -11.449119156852984 None\n",
      "конфликт X yarn : раздор NOUN -12.098969531659606 None\n",
      "конфликт X yarn : ссора NOUN -10.859749565390164 None\n",
      "забирать X yarn : набирать VERB -9.924068018278906 None\n",
      "забирать X yarn : собирать VERB -8.770268596015583 None\n",
      "забирать X yarn : комплектовать VERB -14.38474750633727 None\n",
      "забирать X yarn : вербовать VERB -13.111041363996659 None\n",
      "забирать X yarn : залучать VERB -14.139625048304286 None\n",
      "сковородка X yarn : сковорода NOUN -12.033372249173793 None\n",
      "впоследствии ADV yarn : затем ADV -8.178040913119712 0.31609775090326603\n",
      "впоследствии ADV yarn : с X -4.45008658009755 None\n",
      "впоследствии ADV yarn : после X -6.881269033189423 None\n",
      "впоследствии ADV yarn : потом ADV -7.003049606872163 None\n",
      "выбрасывать X yarn : высылать VERB -10.483523339791583 None\n",
      "выбрасывать X yarn : остракизму NOUN -19.06687873346149 None\n",
      "выбрасывать X yarn : удалять VERB -10.853496996426916 None\n",
      "выбрасывать X yarn : сживать VERB -14.02992613104786 None\n",
      "выбрасывать X yarn : прогонять VERB -12.524406772954684 None\n",
      "выбрасывать X yarn : вытеснять VERB -11.38301475320506 None\n",
      "выбрасывать X yarn : спроваживать VERB -13.549425836996782 None\n",
      "выбрасывать X yarn : ссылать VERB -11.441283661329036 None\n",
      "выбрасывать X yarn : вытуривать VERB -14.330680285066993 None\n",
      "выбрасывать X yarn : выживать VERB -10.673889145504559 None\n",
      "выбрасывать X yarn : выселять VERB -12.386024054671275 None\n",
      "выбрасывать X yarn : исключать VERB -9.866992819389166 None\n",
      "выбрасывать X yarn : выкадить VERB -19.06687873346149 None\n",
      "выбрасывать X yarn : выкидывать VERB -10.92510652880504 None\n",
      "выбрасывать X yarn : выпроваживать VERB -12.58836909125292 None\n",
      "выбрасывать X yarn : выкуривать VERB -12.27341260088148 None\n",
      "выбрасывать X yarn : выпирать VERB -12.493198566500844 None\n",
      "выбрасывать X yarn : упечь VERB -19.06687873346149 None\n",
      "выбрасывать X yarn : выталкивать VERB -11.876202699129282 None\n",
      "выбрасывать X yarn : изводить VERB -12.123756310642062 None\n",
      "выбрасывать X yarn : выводить VERB -9.570382453029572 None\n",
      "выбрасывать X yarn : выдворять VERB -13.846522908383164 None\n",
      "выбрасывать X yarn : гнать VERB -10.147425564886037 None\n",
      "выбрасывать X yarn : изгонять VERB -11.087197431073749 None\n",
      "выбрасывать X yarn : выгонять VERB -10.312402427177323 None\n",
      "урна X yarn : ваза NOUN -11.285740223616473 None\n",
      "обследовать X yarn : проверить VERB -19.06687873346149 None\n",
      "обследовать X yarn : испытать VERB -17.6805843723416 None\n",
      "обследовать X yarn : опробовать VERB -12.586834171534836 None\n",
      "свалка X yarn : свал NOUN -16.233665389405274 None\n",
      "свалка X yarn : помойка NOUN -12.084944056305101 None\n",
      "похищать X yarn : прикарманивать VERB -14.697430880994467 None\n",
      "похищать X yarn : присваивать VERB -11.139915188598511 None\n",
      "похищать X yarn : обкрадывать VERB -12.261156180044503 None\n",
      "похищать X yarn : красть VERB -11.887570763957456 None\n",
      "похищать X yarn : обворовывать VERB -13.383298966122808 None\n",
      "похищать X yarn : таскать VERB -10.896410155130816 None\n",
      "похищать X yarn : воровать VERB -11.085145446769603 None\n",
      "твердый X yarn : крепкий ADJ -9.446616532660201 None\n",
      "твердый X yarn : прочный ADJ -10.41883273362649 None\n",
      "твердый X yarn : жесткий ADJ -9.971724771294424 None\n",
      "отходы X yarn : хлам NOUN -11.866453840516533 None\n",
      "отходы X yarn : мусор NOUN -11.065858772137839 None\n",
      "отходы X yarn : отброс NOUN -13.24383283797847 None\n",
      "отходы X yarn : помои NOUN -12.8623209708928 None\n",
      "отходы X yarn : отбросы NOUN -13.73415994019612 None\n",
      "отходы X yarn : дрянь NOUN -11.069551910463392 None\n",
      "задерживать X yarn : удерживать VERB -9.74428167913964 None\n",
      "задерживать X yarn : улавливать VERB -10.677746212112769 None\n",
      "возбуждать X yarn : наталкивать VERB -14.18407681087512 None\n",
      "возбуждать X yarn : подвигнуть VERB -13.267786079000963 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "возбуждать X yarn : поджигать VERB -11.478555056126266 None\n",
      "возбуждать X yarn : оперять VERB -14.776419292313099 None\n",
      "возбуждать X yarn : трогать VERB -10.338614571965312 None\n",
      "возбуждать X yarn : толкать VERB -10.787435245748824 None\n",
      "возбуждать X yarn : подстрекать VERB -13.100731994337798 None\n",
      "возбуждать X yarn : горячить VERB -14.74939061992518 None\n",
      "возбуждать X yarn : мутить VERB -12.457529490294108 None\n",
      "возбуждать X yarn : подгонять VERB -11.661991157845364 None\n",
      "возбуждать X yarn : вызывать VERB -8.250787236909202 None\n",
      "возбуждать X yarn : подбивать VERB -11.553169485621785 None\n",
      "возбуждать X yarn : воспалять VERB -12.494596190767481 None\n",
      "возбуждать X yarn : влиять VERB -10.476063402174638 None\n",
      "возбуждать X yarn : возжигать VERB -14.176529605239736 None\n",
      "возбуждать X yarn : волновать VERB -10.43208029997099 None\n",
      "возбуждать X yarn : задирать VERB -11.138833132586713 None\n",
      "возбуждать X yarn : раздувать VERB -11.517269568306958 None\n",
      "возбуждать X yarn : подогревать VERB -12.20203095549063 None\n",
      "возбуждать X yarn : подбадривать VERB -12.277906990469319 None\n",
      "возбуждать X yarn : воспламенять VERB -13.17523452163572 None\n",
      "возбуждать X yarn : разжигать VERB -11.981814439508941 None\n",
      "возбуждать X yarn : натравлять VERB -14.139625048304286 None\n",
      "возбуждать X yarn : науськивать VERB -14.304704798663733 None\n",
      "возбуждать X yarn : приглашать VERB -9.026764583393536 None\n",
      "возбуждать X yarn : подущать VERB -19.06687873346149 None\n",
      "возбуждать X yarn : будить VERB -10.799173068699064 None\n",
      "возбуждать X yarn : задевать VERB -11.657742289541362 None\n",
      "возбуждать X yarn : подговаривать VERB -13.22914828629555 None\n",
      "возбуждать X yarn : подучать VERB -17.275119264233435 None\n",
      "возбуждать X yarn : раззадоривать VERB -14.154223847725438 None\n",
      "возбуждать X yarn : агитировать VERB -12.820771967979926 None\n",
      "возбуждать X yarn : ободрять VERB -11.474008445616672 None\n",
      "возбуждать X yarn : поощрять VERB -11.496951078218837 None\n",
      "возбуждать X yarn : расшевелить VERB -19.06687873346149 None\n",
      "возбуждать X yarn : настраивать VERB -10.824912173229688 None\n",
      "возбуждать X yarn : побуждать VERB -11.057183375718568 None\n",
      "возбуждать X yarn : воодушевлять VERB -12.834430716910967 None\n",
      "возбуждать X yarn : подвинуть VERB -19.06687873346149 None\n",
      "возбуждать X yarn : наущать VERB -16.42782140384623 None\n",
      "возбуждать X yarn : подзадоривать VERB -13.646343734189204 None\n",
      "возбуждать X yarn : поднимать VERB -19.06687873346149 None\n",
      "возбуждать X yarn : дразнить VERB -11.329262450603585 None\n",
      "возбуждать X yarn : воскрылять VERB -17.6805843723416 None\n",
      "возбуждать X yarn : раздражать VERB -10.369700045048845 None\n",
      "возбуждать X yarn : окрылять VERB -12.661650275430649 None\n",
      "возбуждать X yarn : подталкивать VERB -11.270820759145366 None\n",
      "уголовный X yarn : незаконный ADJ -10.701671899043134 None\n",
      "уголовный X yarn : преступный ADJ -10.745457146563611 None\n",
      "уголовный X yarn : разбойничий ADJ -12.383517787695215 None\n",
      "ранее ADV yarn : выше ADV -19.06687873346149 0.030344702300281107\n",
      "украсть X yarn : похитить VERB -19.06687873346149 None\n",
      "украсть X yarn : стянуть VERB -19.06687873346149 None\n",
      "украсть X yarn : стащить VERB -17.45744082102739 None\n",
      "украсть X yarn : выкрасть VERB -19.06687873346149 None\n",
      "украсть X yarn : красть VERB -11.887570763957456 None\n",
      "украсть X yarn : своровать VERB -14.600970614806906 None\n",
      "медаль X yarn : орден NOUN -10.085071410083955 None\n",
      "отвага X yarn : безбоязненность NOUN -16.122439754295048 None\n",
      "отвага X yarn : мужество NOUN -10.635679255212228 None\n",
      "отвага X yarn : доблесть NOUN -11.889096317266292 None\n",
      "отвага X yarn : стойкость NOUN -11.847236693330753 None\n",
      "отвага X yarn : несгибаемость NOUN -15.888824903113544 None\n",
      "отвага X yarn : храбрость NOUN -11.20515165563751 None\n",
      "отвага X yarn : решимость NOUN -11.321010503669221 None\n",
      "отвага X yarn : неустрашимость NOUN -14.111051675860228 None\n",
      "отвага X yarn : непреклонность NOUN -13.677807003644988 None\n",
      "отвага X yarn : стоицизм NOUN -14.279386990679443 None\n",
      "отвага X yarn : смелость NOUN -10.848091577860009 None\n",
      "отвага X yarn : бесстрашие NOUN -12.703850629921025 None\n",
      "взятие X yarn : добывание NOUN -12.630728365092061 None\n",
      "взятие X yarn : приём NOUN -19.06687873346149 None\n",
      "взятие X yarn : сбор NOUN -10.008291916712844 None\n",
      "взятие X yarn : добыча NOUN -10.103078490605913 None\n",
      "взятие X yarn : получение NOUN -9.611476774870166 None\n",
      "взятие X yarn : приобретение NOUN -10.594055489781192 None\n",
      "взятие X yarn : добывание NOUN -12.630728365092061 None\n",
      "взятие X yarn : приём NOUN -19.06687873346149 None\n",
      "взятие X yarn : сбор NOUN -10.008291916712844 None\n",
      "взятие X yarn : добыча NOUN -10.103078490605913 None\n",
      "взятие X yarn : получение NOUN -9.611476774870166 None\n",
      "взятие X yarn : приобретение NOUN -10.594055489781192 None\n"
     ]
    }
   ],
   "source": [
    "# Отбор сложных слов, превращение их в подкласс сложных слов и поиск замен\n",
    "# несложные слова также остаются на своих местах\n",
    "def selecting_complex(tokens, base_type='yarn'):\n",
    "    complex_words = []\n",
    "    for token in tokens:\n",
    "        if token.is_complex(global_threshold, use_min):\n",
    "            comp_token = Complex_word(token) # токен становится Сложным словом\n",
    "            comp_token.convert_universal() # превращаем теги майстем в теги universal (чтоб искать сходство для словарных синонимов)\n",
    "            comp_token.search_substituts(base_type=base_type)\n",
    "            complex_words.append(comp_token)\n",
    "            # код для принтов\n",
    "            if comp_token.substituts:\n",
    "                for syn in comp_token.substituts:\n",
    "                    print (comp_token.lexem, comp_token.pos, base_type, ':', syn.lexem, syn.pos, syn.complexity, syn.similarity)\n",
    "        else:\n",
    "            complex_words.append(token)\n",
    "    return complex_words\n",
    "\n",
    "complex_words = selecting_complex(tokens, 'yarn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### теперь, когда для каждого сложного слова есть список его синонимов с нужными параметрами, можно делать модель на н-граммах\n",
    "### контекстное окно: 10 слов (по 5 слева и справа), можно задавать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for token in complex_words:\n",
    "    if isinstance(token, Complex_word):\n",
    "        if token.substituts: # окна контекста строим для тех сложных слов, для которых есть варианты замен\n",
    "            token.make_window(complex_words, window = 10)\n",
    "            '''\n",
    "            # вывод\n",
    "            context_lem = [c.lexem for c in token.context]\n",
    "            print(token.num, token.text, token.place, ':', context_lem)'''\n",
    "            for cont in token.context:\n",
    "                # вычисляем вероятность цепочки\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загружаем всё необходимое для создания языковой модели, а именно списки н-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lang_model():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

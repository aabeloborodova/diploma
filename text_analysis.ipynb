{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from nltk.corpus import stopwords\\nstop_words = stopwords.words(\"russian\")'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# импорты\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "from string import punctuation\n",
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "import csv\n",
    "import gensim\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import pymystem3\n",
    "m = pymystem3.Mystem() #для использования лемматизации\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"russian\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# читает из файла, убирает двойные пробелы и ручные переносы, последний \\n\n",
    "def reading(file):\n",
    "    f = open('texts\\\\{}.txt'.format(file), 'r', encoding='utf-8')\n",
    "    text = f.read()\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace('-\\n', '')\n",
    "    if text[-1] == '\\n': # убираем последний \\n, если такой есть \n",
    "        text = text[:-1]\n",
    "    f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка необходимых лексических баз:   \n",
    "### словарей частот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack(data):\n",
    "    input = open(data, 'rb')\n",
    "    obj = pickle.load(input)\n",
    "    input.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загружаем частоты лем униграмм\n",
    "unigrams = unpack('1stemgrams.data')\n",
    "# убрали пробел из начала слов\n",
    "unigrams = {w[1:]:f for w,f in unigrams.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = unpack('2grams.data')\n",
    "# убрали пробел из начала слов, пунктуацию (кроме дефисов) и двойные пробелы\n",
    "bigrams  = {''.join([i for i in w[1:] if i not in punctuation.replace('-','')]).replace('  ',' '):f for w,f in bigrams.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['дальнейший допрос',\n",
       " 'оканчивать преступление',\n",
       " 'развитие христианство',\n",
       " 'и затонуть',\n",
       " 'подразумевать она',\n",
       " 'и однозначный',\n",
       " '2 введение',\n",
       " 'желать услышать',\n",
       " 'являться недооценка',\n",
       " 'закрепляться по']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = unpack('3grams.data')\n",
    "# убрали пробел из начала слов, пунктуацию (кроме дефисов) и двойные пробелы\n",
    "trigrams = {''.join([i for i in w[1:] if i not in punctuation.replace('-','')]).replace('  ',' '):f for w,f in trigrams.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в лифт я',\n",
       " 'что сам русский',\n",
       " 'почему ты думать',\n",
       " 'фестиваль в кольмар',\n",
       " 'твердость и прочность',\n",
       " 'тот число руководитель',\n",
       " 'судьба решать иначе',\n",
       " 'мысль рождаться в',\n",
       " 'мой учение то',\n",
       " 'да только что']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trigrams.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка необходимых лексических баз:   \n",
    "### модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# загрузка модели\n",
    "def model_loading(file):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(file, binary=False)\n",
    "    model.init_sims(replace=True)\n",
    "    print('Done!') \n",
    "    return model\n",
    "\n",
    "model = model_loading('news_upos_cbow_600_2_2018.vec') #на загрузку тратится минут 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = model_loading('ruwikiruscorpora-nobigrams_upos_skipgram_300_5_2018.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка необходимых лексических баз:   \n",
    "### словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загрузка словаря ASIS\n",
    "with open('syns.data', 'rb') as f:\n",
    "     asis = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка необходимых лексических баз:   \n",
    "### минимумов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_minimum(typ=['A1','B1','B2'][0]):\n",
    "    # всякие непонятные куски, портящие статистику по минимумам:\n",
    "    to_remove = ['ми', 'вод', 'кий', 'ре','вая', 'ча', 'то быть', 'чка', 'стен']\n",
    "    with open('{}.txt'.format(typ), 'r', encoding='utf-8') as file:\n",
    "        lemtokens = [morph.parse(i)[0].normal_form for i in file.read().lower().split('\\n') if morph.parse(i)[0].normal_form not in to_remove] #делаем список лемм слов\n",
    "        minimum = list(set(lemtokens)) #убираем повторы\\\n",
    "    return minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "minimum = load_minimum('B1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание параметров способа определения сложности (частота или информационное содержание), идентификации слова как сложного (основываться только на минимуме/нет) и порога сложности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ПАРАМЕТРЫ анализа слов\n",
    "complexity_type = 'inf' # альтернатива: freq \n",
    "use_min=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение порога сложности на основе коэффициента информации (из униграмм) и минимумов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_threshold():\n",
    "    # чем информационное содержание меньше, чем сложнее слово (с уменьшением дроби логарифм уменьшается тоже)\n",
    "    det = sum(f for f in unigrams.values())+1\n",
    "    # словарь цнф.содер и количества слов с таким коэф. в выбранном минимуме\n",
    "    inf_coef = Counter([round(math.log((unigrams.get(w)+1)/det),1) for w in minimum if w in unigrams])\n",
    "    # может быть очень низким (<17) для очень редких слов (матерь??) или опечаток, но в основном колеблется ок -9\n",
    "    print(inf_coef.most_common(10))\n",
    "    return np.median(list(inf_coef.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-9.3, 68), (-9.4, 49), (-9.8, 47), (-9.7, 46), (-8.9, 45), (-9.6, 45), (-9.5, 44), (-10.2, 40), (-9.0, 37), (-9.2, 37)]\n"
     ]
    }
   ],
   "source": [
    "global_threshold = make_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Таблица конверсии в UPoS из тэгов Mystem: в моделях используется первый, а при анализе текстов второй. Таблица конверсии из тегов Pymorphy2 - используется при назначении части речи словарным словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Таблица конверсии в UPoS из тэгов Mystem\n",
    "# словарь, переводящий теги mystem в universal теги моделей\n",
    "mystem_tags = {'A' : 'ADJ',\n",
    "       'ADV' : 'ADV',\n",
    "       'ADVPRO' : 'ADV',\n",
    "       'ANUM' : 'ADJ',\n",
    "       'APRO' : 'DET',\n",
    "       'COM' : 'ADJ',\n",
    "       'CONJ' : 'SCONJ',\n",
    "       'INTJ' : 'INTJ',\n",
    "       'NONLEX' : 'X',\n",
    "       'NUM' : 'NUM',\n",
    "       'PART' : 'PART',\n",
    "       'PR' : 'ADP',\n",
    "       'S' : 'NOUN',\n",
    "       'SPRO' : 'PRON',\n",
    "       'UNKN' : 'X',\n",
    "       'V' : 'VERB',\n",
    "       'X' : 'X',\n",
    "      'PROPN' : 'PROPN'} #последних 2 тегов в майстеме нет, но они задаются в классе для слов в соответсвующими пометами\n",
    "\n",
    "# словарь, переводящий теги пайморфи в universal теги моделей\n",
    "pymorphy_tags = {'ADJF':'ADJ',\n",
    "    'ADJS' : 'ADJ',\n",
    "    'ADVB' : 'ADV',\n",
    "    'COMP' : 'ADV',\n",
    "    'GRND' : 'VERB',\n",
    "    'INFN' : 'VERB',\n",
    "    'NOUN' : 'NOUN',\n",
    "    'PRED' : 'ADV',\n",
    "    'PRTF' : 'ADJ',\n",
    "    'PRTS' : 'VERB',\n",
    "    'VERB' : 'VERB'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные классы: Токен (родительский), Сложное слово и Замена (дочерние)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Token():\n",
    "    def __init__(self, w):\n",
    "        \n",
    "        self.num = None # номер в тексте\n",
    "        self.complexity = None # сложность слова\n",
    "        self.av_similarity = None\n",
    "        \n",
    "        # три варианта инициализации: \n",
    "        ## из анализа текста, \n",
    "        ## из уже имеющегося объекта (для дочернего класса ComplexWord) \n",
    "        ## из строки\n",
    "        \n",
    "        if isinstance(w, dict): # если получили результат работы mystem\n",
    "            \n",
    "            self.text = w['text']  # сам токен\n",
    "            self.len = len(w['text']) # его длина\n",
    "            \n",
    "            # определяет, сделан ли анализ и, соответственно, рассматривать ли как слово, требующее упрощения\n",
    "            gram = w.get('analysis')\n",
    "            if gram:\n",
    "                self.lexem = gram[0]['lex']  # лемма\n",
    "                \n",
    "                if not self.named_entity(gram[0]):  # именованная сущность или нет\n",
    "                    self.pos = self.pos_tag(gram[0]['gr'])  # часть речи\n",
    "                else:\n",
    "                    self.pos = 'PROPN' # universal tag for named entity - у майстема таких нет\n",
    "                \n",
    "                    \n",
    "            elif any(p in w['text'] for p in punctuation+'–«»'): # если это знак пунктуации (может быть с пробелом!)\n",
    "                self.lexem = '_PUNKTUATION_'\n",
    "                self.pos = None\n",
    "            \n",
    "            elif not re.findall('\\S',w['text']): # если это только пробельные символы\n",
    "                self.lexem = '_SPACE_'\n",
    "                self.pos = None\n",
    "                \n",
    "            # остальное - неизвестная и ненужная ерунда?\n",
    "            else:\n",
    "                self.lexem = '_UNK_'\n",
    "                self.pos = 'X' # universal tag for unknown\n",
    "            \n",
    "            \n",
    "        elif isinstance(w, Token): # для определения объектов дочернего класса ComplexWord\n",
    "            self.text = w.text\n",
    "            self.num = w.num\n",
    "            self.lexem = w.lexem \n",
    "            self.len = w.len\n",
    "            self.pos = w.pos\n",
    "            self.complexity = w.complexity\n",
    "            \n",
    "        \n",
    "        elif isinstance(w, str): # если хотим как класс токен определить строку, полученную из словаря или модели\n",
    "            self.text = w\n",
    "            self.pos = None\n",
    "            self.lexem = w\n",
    "            self.len = len(w)\n",
    "            self.num = None\n",
    "            self.complexity = None\n",
    "            \n",
    "        \n",
    "    # вытаскивает часть речи из разбора майстем\n",
    "    def pos_tag(self,gram):\n",
    "        if ',' in gram:\n",
    "            gram = gram.split(',')[0]\n",
    "        if '=' in gram:\n",
    "            gram = gram.split('=')[0]\n",
    "        return gram\n",
    "        \n",
    "    # определяет по тегам, является ли именованной сущностью\n",
    "    def named_entity(self,gram):\n",
    "        markers = {'сокр': ' - сокращение', 'фам': ' - фамилия', 'имя': ' - имя собственное', 'гео': ' - название места', }\n",
    "        if any(m in gram['gr'] for m in markers.keys()):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def complexity_params(self, param = 'freq'):\n",
    "        # если по частотности\n",
    "        if param == 'freq':\n",
    "            self.complexity = unigrams.get(self.lexem, 0)\n",
    "            \n",
    "        # если по коэффициенту информативности. Отрицательное значение. Чем он меньше, тем сложнее\n",
    "        elif param == 'inf':\n",
    "            self.complexity = math.log((unigrams.get(self.lexem, 0)+1)/(sum(f for f in unigrams.values())+1))\n",
    "        return self\n",
    "    \n",
    "    def is_complex(self, threshold = global_threshold, use_min = False):\n",
    "        exceptions = ['_PUNKTUATION_', '_SPACE_', '_UNK_']\n",
    "        # проверка, что это слово и что его нужно рассматривать как сложное (не нарицательное)\n",
    "        if not any(exception in self.lexem for exception in exceptions) and self.pos not in ['PROPN']:\n",
    "            \n",
    "            # если показатель сложности - вхождение в минимум\n",
    "            if use_min:\n",
    "                if self.lexem not in minimum:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "\n",
    "            # если показатель сложности - пороговое значение сложности\n",
    "            else:\n",
    "                if self.complexity < threshold:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def convert_universal(self):\n",
    "        if self.pos in mystem_tags:\n",
    "            self.pos = mystem_tags[self.pos]\n",
    "        else:\n",
    "            self.pos = 'X' # Х - universal тег для неизвестных слов\n",
    "        return self\n",
    "    \n",
    "    # нужна в двух случаях: для Замен, полученных из словарей, чтобы приписывать им соответствующий параметр,\n",
    "    # и для подсчета адекватности слова контексту\n",
    "    def cos_sim(self, context):\n",
    "        #print(self.lexem, target.lexem, self.pos, target.pos)\n",
    "        subst_query = str(self.lexem+'_'+self.pos)\n",
    "        target_query = str(context.lexem+'_'+context.pos)\n",
    "        if subst_query in model and target_query in model:\n",
    "            return model.similarity(subst_query, target_query)\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Substitution(Token):\n",
    "    def __init__(self, w):\n",
    "        super().__init__(w)\n",
    "        self.similarity = None\n",
    "        self.fitness = None\n",
    "        self.closeness = None\n",
    "    \n",
    "    # для слов из словаря и тезауруса: определяем тег пайморфи, переводим в формат universal - так быстрее, чем майстемом\n",
    "    def tagging(self, w):\n",
    "        tag = morph.parse(w)[0].tag.POS\n",
    "        if tag in pymorphy_tags:\n",
    "            return pymorphy_tags[tag]\n",
    "        else:\n",
    "            return 'X' # Х - universal тег для неизвестных слов\n",
    "    \n",
    "    # приписываем недостающие атрибуты словам, взятым из словаря или тезауруса\n",
    "    def setting_atr(self, target):\n",
    "        self.pos = self.tagging(self.lexem)\n",
    "        self.complexity_params(complexity_type)\n",
    "        self.similarity = self.cos_sim(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Complex_word(Token):\n",
    "    def __init__(self, w):\n",
    "        super().__init__(w)\n",
    "        self.substituts = None\n",
    "        self.place = None\n",
    "        self.context = None\n",
    "        self.easier = []\n",
    "        \n",
    "    # список замен, в зависимости от выбранной базы\n",
    "    def search_substituts(self, base_type='model'):\n",
    "        \n",
    "        # поиск по модели\n",
    "        def model_search(lexem, pos):\n",
    "            query = str(lexem+'_'+pos)\n",
    "            #print(query)\n",
    "            if query in model:\n",
    "                # формируем список квазисинонимов той же части речи\n",
    "                # при этом превращаем их в объекты соответствующего класса\n",
    "                syn_tokens = []\n",
    "                for syn, sim in model.most_similar(positive=[query]):\n",
    "                    syn_text = syn[:syn.find('_')] # текст до части речи\n",
    "                    \n",
    "                    syn_tok = Substitution(syn_text) # из текстовой строки инициализируем объект класса\n",
    "                    syn_tok.pos = syn[syn_tok.len+1:] # часть речи\n",
    "                    \n",
    "                    syn_tok.complexity_params(complexity_type) # сложность по функции в зависимости от выбранного параметра\n",
    "                    \n",
    "                    syn_tok.similarity = sim # а близость по параметру модели\n",
    "                    \n",
    "                    syn_tokens.append(syn_tok)\n",
    "                    \n",
    "                return syn_tokens\n",
    "            else:\n",
    "                return [] \n",
    "\n",
    "        # поиск по YARN\n",
    "        def yarn_search(target, filepath = 'yarn-synsets1.csv'):\n",
    "            with open(filepath, \"r\", newline=\"\") as file: # постепенный просмотр файла с синсетами (множествами синонимов)\n",
    "                reader = csv.DictReader(file, delimiter=';')\n",
    "                lst = []\n",
    "                for i,row in enumerate(reader):\n",
    "                    cur_line = row['words'].split(';') # считываем колонку с синсетами\n",
    "                    if len(cur_line)>1:\n",
    "                        if target.lexem in cur_line:\n",
    "                            del(reader)\n",
    "                            for c in cur_line:\n",
    "                                if ' ' not in c and c!=target.lexem: # формируем список однословных синонимов\n",
    "                                    sub_tok = Substitution(c)\n",
    "                                    \n",
    "                                    sub_tok.setting_atr(target)\n",
    "                                    \n",
    "                                    if sub_tok not in lst:\n",
    "                                        lst.append(sub_tok) \n",
    "                            #TODO: выделить неоднословные в отдельный класс и поискать их частотность по n-граммам?\n",
    "                            break\n",
    "                #print(lst)\n",
    "                return lst \n",
    "        \n",
    "        #поиск по ASIS\n",
    "        def asis_search(target):\n",
    "            if target.lexem in asis:\n",
    "                lst = []\n",
    "                for s in asis[target.lexem]:\n",
    "                    if ' ' not in s: # формируем список однословных синонимов\n",
    "                        sub_tok = Substitution(s)\n",
    "                        sub_tok.setting_atr(target)\n",
    "                        lst.append(sub_tok)\n",
    "                return lst\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        \n",
    "        if base_type == 'model':\n",
    "            self.substituts = model_search(self.lexem, self.pos)\n",
    "            \n",
    "        if base_type == 'yarn':\n",
    "            self.substituts = yarn_search(self)\n",
    "        \n",
    "        if base_type == 'asis':\n",
    "            self.substituts = asis_search(self)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def find_easier(self, use_min = use_min, threshold = global_threshold):\n",
    "        for sub in self.substituts:\n",
    "            if not sub.is_complex(threshold = threshold, use_min = use_min):\n",
    "                if sub.complexity > self.complexity:\n",
    "                    self.easier.append(sub)\n",
    "        return self\n",
    "    \n",
    "    def make_window(self, tokens, window = 10):\n",
    "        context = [self]\n",
    "        left_ind = self.num-1\n",
    "        right_ind = self.num+1\n",
    "        ind = 0\n",
    "        # добавляем по одному слову слева и/или справа, пока не наберется window + само слово\n",
    "        while len(context)<window+1:\n",
    "            while left_ind >= 0:\n",
    "                left_w = tokens[left_ind]\n",
    "                left_ind-=1\n",
    "                # проверка, что это слово\n",
    "                if any(exception in left_w.lexem for exception in ['_PUNKTUATION_', '_SPACE_', '_UNK_']):\n",
    "                    continue\n",
    "                else:\n",
    "                    context[:0] = [left_w] #вставляем слово слева от цепочки\n",
    "                    ind+=1 # индекс слова сдвигается\n",
    "                    break\n",
    "\n",
    "            while right_ind < len(tokens):\n",
    "                right_w = tokens[right_ind]\n",
    "                right_ind+=1\n",
    "                # проверка, что это слово и что его нужно рассматривать как сложное (не нарицательное)\n",
    "                if any(exception in right_w.lexem for exception in ['_PUNKTUATION_', '_SPACE_', '_UNK_']):\n",
    "                    continue\n",
    "                else:\n",
    "                    context.append(right_w) # справа от цепочки\n",
    "                    break\n",
    "        self.place = ind\n",
    "        self.context = context\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция анализа текста и формирования из него списка токенов с соотв.атрибутами. Вход: текст в виде строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#анализ текста \n",
    "def text_structuring(text, param, threshold, use_min):\n",
    "    # анализирует текст \n",
    "    analysis = m.analyze(text)\n",
    "    tokens = []\n",
    "    for i, w in enumerate(analysis): # состаляем список объектов Tokens\n",
    "        token = Token(w)\n",
    "        token.num = i # добавляем токену в атрибуты его номер в тексте\n",
    "        token.complexity_params(param) # переопределяем сложность на основе выбранного параметра\n",
    "        token.convert_universal() # превращаем POS в universal формат\n",
    "        #print(token.num, token.text, token.lexem, token.pos, token.complexity, token.is_complex(threshold, use_min))\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для нахождения сложных слов, превращения их в подкласс сложных слов и поиска замен для них. Вход: список объектов класса Токен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def selecting_complex(tokens, base_type=['yarn','model','asis'][0], threshold = global_threshold, use_min = use_min):\n",
    "    complex_words = []\n",
    "    actualy_complex = []\n",
    "    to_simplify = []\n",
    "    for token in tokens:\n",
    "        if token.is_complex(threshold, use_min):\n",
    "            comp_token = Complex_word(token) # токен становится Сложным словом\n",
    "            \n",
    "            comp_token.search_substituts(base_type=base_type)\n",
    "            \n",
    "            complex_words.append(comp_token)\n",
    "            \n",
    "            # код для принтов\n",
    "            '''\n",
    "            if comp_token.substituts:\n",
    "                for syn in comp_token.substituts:\n",
    "                    print (comp_token.lexem, comp_token.complexity, base_type, ':', syn.lexem, syn.complexity, syn.similarity)\n",
    "            '''\n",
    "            if comp_token.substituts:\n",
    "                actualy_complex.append(comp_token)\n",
    "                comp_token.find_easier(threshold, use_min)\n",
    "                if comp_token.easier:\n",
    "                    to_simplify.append(comp_token)\n",
    "                    \n",
    "            '''if comp_token.easier:\n",
    "                for syn in comp_token.easier:\n",
    "                    print (comp_token.lexem, comp_token.pos, base_type, ':', syn.lexem, syn.pos, syn.complexity, syn.similarity)\n",
    "            '''\n",
    "        else:\n",
    "            complex_words.append(token)\n",
    "    return complex_words, actualy_complex, to_simplify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Вероятность контекстного окна на основе логарифма + Лапласса. Контекстное окно: 2n+1 слов (по n слева и справа), можно задавать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_dict = {0: {}, 1: unigrams, 2: bigrams, 3: trigrams}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вообще при н=1 должно быть не деление на V, а деление на объем корпуса - количество вхождений слов. Те подсчитать сумму значений частот униграмм. Но пока для 3грамм работает нормально. Также криво, вроде бы, с логарифмом... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram_prob(ngram, n, use_log= False):\n",
    "    c1 = ' '.join(ngram[-n:]) # в числителе частота строки длины n\n",
    "    c2 = ' '.join(ngram[-n:-1]) # в знаменателе - строки без последнего символа\n",
    "    d = ngrams_dict.get(n) # для поиска числителя берем словарь n-грамм\n",
    "    d2 = ngrams_dict.get(n-1) # для поиска знаменателя - словарь n-1-грамм\n",
    "    V = len(d)\n",
    "    #len(ngrams_dict.get(n-1,len(unigrams))) # сглаживание лапласса: добавляем размер словаря знаменателя\n",
    "    p1 = d.get(c1,0)+1\n",
    "    p2 = d2.get(c2,0)+V\n",
    "    \n",
    "    result =  p1/p2\n",
    "    \n",
    "    #print('\\t',c1, '/', c2, ':' , p1-1, '/', p2-V, '(', p1, '/', p2, ')', '=', result)\n",
    "    \n",
    "    if use_log:\n",
    "        return math.log(p1)-math.log(p2)\n",
    "    else:\n",
    "        return p1/p2\n",
    "    \n",
    "def context_prob(ngrams, use_log= False):\n",
    "    if use_log:\n",
    "        p_context = 0.0\n",
    "    else:\n",
    "        p_context = 1.0\n",
    "    for ngram in ngrams:\n",
    "        p = ngram_prob(ngram, 3, use_log= use_log)\n",
    "        #print(ngram, p)\n",
    "        if use_log:\n",
    "            p_context+=p\n",
    "        else:\n",
    "            p_context*=p\n",
    "    return p_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датафрейма с текстами и измерение потенциала системы для разных словарных баз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('texts1.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'],axis=1)\n",
    "df = df.drop_duplicates(subset='texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['politics',\n",
       " 'culture',\n",
       " 'sport',\n",
       " 'incident',\n",
       " 'society',\n",
       " 'business',\n",
       " 'science',\n",
       " 'computers',\n",
       " 'world']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubrics = list(set(df['rubrics']))\n",
    "rubrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sample(n=15, mode=['random','first'][0], lst = None):\n",
    "    rubric = list(set(df['rubrics'])) # список рубрик\n",
    "    text_rubrics = df.filter(items=['texts', 'rubrics']) # таблица текст-рубрика\n",
    "    text_for_potential = []\n",
    "    for r in rubric:\n",
    "        rub_texts = []\n",
    "        for l in range(len(text_rubrics)):\n",
    "            if text_rubrics.loc[l][1]==r:\n",
    "                rub_texts.append(text_rubrics.loc[l][0])\n",
    "                if mode == 'first':\n",
    "                    if len(rub_texts)>n-1:\n",
    "                        break\n",
    "        if mode == 'random':\n",
    "            rub_texts = [rub_texts[l] for l in lst] # делаем подвыборку в н текстов\n",
    "            \n",
    "        text_for_potential.extend(rub_texts) \n",
    "    return text_for_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_potential(n = 5, base = ['yarn','model','asis'][0], use_min = False):\n",
    "    \n",
    "    text_for_potential = make_sample(n)\n",
    "    #print(text_for_potential)\n",
    "    \n",
    "    positif = 0\n",
    "    total1 = 0\n",
    "    #total2 = 0\n",
    "    \n",
    "    for text in text_for_potential:\n",
    "        tokens = text_structuring(text, complexity_type, global_threshold, use_min)        \n",
    "        complex_words, actually_complex, comlex_easier = selecting_complex(tokens, base, threshold = global_threshold, use_min = use_min)\n",
    "        '''for token in actually_complex:\n",
    "            print(token.num, token.text, token.lexem, token.complexity, token.easier)'''\n",
    "        positif += len(comlex_easier)\n",
    "        total1 += len(actually_complex)\n",
    "        \n",
    "        '''positif += sum([sum([1 for sub in token.easier if sub in minimum]) for token in comlex_easier])\n",
    "        total1 += len(actually_complex)\n",
    "        total2 += len(comlex_easier)\n",
    "        \n",
    "    pot1 = positif/total1 if total1 else 0\n",
    "    pot2 = positif/total2 if total2 else 0\n",
    "    \n",
    "    return pot1, pot2'''\n",
    "        \n",
    "    pot1 = positif/total1 if total1 else 0\n",
    "    \n",
    "    return pot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = random.sample(range(15),5)\n",
    "model_potential = measure_potential(n = 5, base = 'model', mode = 'random', lst=lst)\n",
    "model_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asis_potential = measure_potential(n = 5, base = 'asis', mode = 'random', lst=lst)\n",
    "asis_potential_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yarn_potential = measure_potential(n = 5, base = 'yarn', mode = 'random', lst=lst)\n",
    "yarn_potential_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Большая и страшная функция для сложных токенов в тексте, вычисляющая для них всяческие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>исходное</th>\n",
       "      <th>замена</th>\n",
       "      <th>индекс</th>\n",
       "      <th>контекст</th>\n",
       "      <th>сложность</th>\n",
       "      <th>разница_сложности</th>\n",
       "      <th>словарность</th>\n",
       "      <th>близость</th>\n",
       "      <th>разница_вероятности</th>\n",
       "      <th>разница_лог_вероятности</th>\n",
       "      <th>контекстуальность</th>\n",
       "      <th>класс</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [исходное, замена, индекс, контекст, сложность, разница_сложности, словарность, близость, разница_вероятности, разница_лог_вероятности, контекстуальность, класс]\n",
       "Index: []"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df1 = pd.DataFrame(columns=['исходное','замена','индекс','контекст','сложность','разница_сложности',\n",
    "                                 'словарность', 'близость','разница_вероятности','разница_лог_вероятности',\n",
    "                                 'контекстуальность','класс'])\n",
    "class_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_frame(window=5, base = ['yarn','model','asis'][0], n=3, t=5, algorithm = ['ngram','random_three'][0], baseline=0):\n",
    "    # алогритм классификации слова как сложного/простого\n",
    "    global class_df\n",
    "    \n",
    "    def ngram_algorithm(best_sub):\n",
    "        if best_sub:\n",
    "            if sub.fitness > best_sub.fitness:\n",
    "                return sub\n",
    "            elif sub.fitness == best_sub.fitness:\n",
    "                if sub.complexity - best_sub.complexity > baseline: \n",
    "                    # принимаю условие, что вероятность должна быть больше исходной (baseline=0) \n",
    "                    # можно модифицировать на \"вероятность не более чем на _ меньше исходной (baseline=-0.01, например)\n",
    "                    return sub\n",
    "            else:\n",
    "                return best_sub\n",
    "        else:\n",
    "            return best_sub\n",
    "            \n",
    "    def transpose(matr):\n",
    "        res=[]\n",
    "        n=len(matr)\n",
    "        m=len(matr[0])\n",
    "        for j in range(m):\n",
    "            tmp=[]\n",
    "            for i in range(n):\n",
    "                tmp=tmp+[matr[i][j]]\n",
    "            res=res+[tmp]\n",
    "        return res\n",
    "            \n",
    "    for text in make_sample(t, mode='first'):\n",
    "        #print(text)\n",
    "        tokens = text_structuring(text, complexity_type, global_threshold, use_min)        \n",
    "        complex_words, actually_complex,complex_easier = selecting_complex(tokens, base, threshold = global_threshold, use_min = False)\n",
    "        pr = [token.lexem for token in actually_complex]\n",
    "        #print(pr)\n",
    "        pr = [token.lexem for token in complex_easier]\n",
    "        #print(pr)\n",
    "        for token in complex_easier:\n",
    "            #['лемма','индекс','контекст','информативность','разница_сложности','словарность',\n",
    "            # 'близость','разница_вероятности','разница_лог_вероятности','контекстуальность','класс']\n",
    "            \n",
    "            new_line = [[]]*12 #будущая часть датафрейма\n",
    "            #print(len(new_line))\n",
    "            new_line[0] = [token.lexem]*len(token.easier) # исходное слово\n",
    "            cls = [0]*len(token.easier) # для таблички - классы\n",
    "            in_min = [] # для таблички - словарность - в минимуме\n",
    "            easier_lexems = [t.lexem for t in token.easier] # для таблички - лексемы замен 1\n",
    "            new_line[1] = easier_lexems\n",
    "            easier_inf = [t.complexity for t in token.easier] # для таблички - сложность замен 3\n",
    "            easier_compl = [t.complexity-token.complexity for t in token.easier] # для таблички - разница сложности 4\n",
    "            new_line[4] = easier_inf\n",
    "            new_line[5] = easier_compl\n",
    "            easier_cos = [sub.cos_sim(token) for sub in token.easier] # для таблички - косинусная близость 6\n",
    "            new_line[7] = easier_cos\n",
    "            \n",
    "\n",
    "            # окна контекста строим для тех сложных слов, для которых есть варианты замен проще, чем исходное\n",
    "            token.make_window(complex_words, window = window) # для подсчетов\n",
    "            easier_places = [token.place]*len(token.easier) # для таблички - место исходного в контексте 1\n",
    "            new_line[2] = easier_places\n",
    "\n",
    "            context_lem = [c.lexem for c in token.context] # для подсчета вероятностей нграмм\n",
    "            context_text = ' '.join([c.text.lower() for c in token.context]) # для таблички - контекст 2\n",
    "            new_line[3] = [context_text]*len(token.easier)\n",
    "\n",
    "            # определение, насколько слово близко с другими словами из контекста\n",
    "            # cos_sim возвращает 0.0, если пара слов не найдена в модели\n",
    "            closeness = np.mean([token.cos_sim(w) for w in token.context if w.lexem!=token.lexem])\n",
    "\n",
    "            text_ngrams = [g for g in ngrams(context_lem, n)] # генерация n-грамм\n",
    "            p_context = context_prob(text_ngrams, use_log=False) # вероятность контекста\n",
    "            p_context_log = context_prob(text_ngrams, use_log=True) # вероятность контекста\n",
    "\n",
    "            \n",
    "            best_sub = None\n",
    "            easier_prob = [] # для таблички - контексная вероятность 7\n",
    "            easier_prob_log = [] # для таблички - log контексная вероятность 8\n",
    "            easier_similarity = [] # для таблички - контексная близость 9\n",
    "            for sub in token.easier:\n",
    "                \n",
    "                # контекст с новым словом\n",
    "                sub_context = token.context[:token.place]+[sub]+token.context[token.place+1:]\n",
    "                # все то же самое\n",
    "                sub.closeness = np.mean([sub.cos_sim(w) for w in sub_context if w.lexem!=sub.lexem])\n",
    "                easier_similarity.append(sub.closeness) # для таблички - контексная близость\n",
    "\n",
    "                sub_context_lem = [t.lexem for t in sub_context]\n",
    "                sub_ngrams = [g for g in ngrams(sub_context_lem, n)]\n",
    "                p_changed_context = context_prob(sub_ngrams, use_log=False)-p_context\n",
    "                easier_prob.append(p_changed_context) # для таблички - контексная вероятность\n",
    "                \n",
    "                p_changed_context2 = context_prob(sub_ngrams, use_log=True)-p_context_log\n",
    "                sub.fitness = p_changed_context2\n",
    "                easier_prob_log.append(p_changed_context2) # для таблички - log контексная вероятность\n",
    "\n",
    "                if sub in minimum:\n",
    "                    in_min.append(1) # словарность\n",
    "                else:\n",
    "                    in_min.append(0)\n",
    "\n",
    "                if algorithm == 'ngram':\n",
    "                    best_sub = ngram_algorithm(best_sub)\n",
    "                    #print('Пока лучший ',best_sub, p_changed_context2)\n",
    "            \n",
    "            new_line[6] = in_min # словарность\n",
    "            new_line[8] = easier_prob # вероятность\n",
    "            new_line[9] = easier_prob_log\n",
    "            new_line[10] = easier_similarity # контекстуальность\n",
    "            \n",
    "            if algorithm == 'ngram' and best_sub:\n",
    "                for i,sub in enumerate(token.easier):\n",
    "                    if sub == best_sub:\n",
    "                        cls[i]=1\n",
    "                        \n",
    "            new_line[11] = cls # класс\n",
    "            \n",
    "            #print(new_line)\n",
    "            # запись в датафрейм\n",
    "            new_line = transpose(new_line)\n",
    "            for line in new_line:\n",
    "                class_df1.loc[len(class_df1)]=line\n",
    "            print(new_line)\n",
    "        \n",
    "        class_df1 = class_df1.drop_duplicates(subset=['исходное','замена','индекс','контекст'])\n",
    "        class_df1.to_csv('class_df_yarn.csv',sep='\\t')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'class_df1' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-e942f435660d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmaking_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'yarn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ngram'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-138-b9e7c2502397>\u001b[0m in \u001b[0;36mmaking_frame\u001b[1;34m(window, base, n, t, algorithm, baseline)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mnew_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mclass_df1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_df1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'class_df1' referenced before assignment"
     ]
    }
   ],
   "source": [
    "making_frame(window=6, base = 'yarn', n=3, t=15, algorithm = 'ngram', baseline=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>исходное</th>\n",
       "      <th>замена</th>\n",
       "      <th>индекс</th>\n",
       "      <th>контекст</th>\n",
       "      <th>сложность</th>\n",
       "      <th>разница_сложности</th>\n",
       "      <th>словарность</th>\n",
       "      <th>близость</th>\n",
       "      <th>разница_вероятности</th>\n",
       "      <th>разница_лог_вероятности</th>\n",
       "      <th>контекстуальность</th>\n",
       "      <th>класс</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мэрия</td>\n",
       "      <td>администрация</td>\n",
       "      <td>0</td>\n",
       "      <td>мэрия екатеринбурга готова провести опрос насе...</td>\n",
       "      <td>-9.758051</td>\n",
       "      <td>2.118905</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488974</td>\n",
       "      <td>-1.765001e-38</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>опрос</td>\n",
       "      <td>исследование</td>\n",
       "      <td>3</td>\n",
       "      <td>екатеринбурга готова провести опрос населения ...</td>\n",
       "      <td>-8.779933</td>\n",
       "      <td>2.464501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512625</td>\n",
       "      <td>-7.517182e-37</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>интерфакс</td>\n",
       "      <td>тасс</td>\n",
       "      <td>3</td>\n",
       "      <td>сквера сообщает агентство интерфакс со ссылкой на</td>\n",
       "      <td>-12.146207</td>\n",
       "      <td>1.029027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688722</td>\n",
       "      <td>2.041090e-35</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.060943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>мэр</td>\n",
       "      <td>депутат</td>\n",
       "      <td>3</td>\n",
       "      <td>ссылкой на заместителя мэра города екатерину к...</td>\n",
       "      <td>-9.544944</td>\n",
       "      <td>1.092480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374717</td>\n",
       "      <td>6.614308e-37</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>опрос</td>\n",
       "      <td>исследование</td>\n",
       "      <td>3</td>\n",
       "      <td>предложением о проведении опроса местных жител...</td>\n",
       "      <td>-8.779933</td>\n",
       "      <td>2.464501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512625</td>\n",
       "      <td>-2.282582e-31</td>\n",
       "      <td>-1.386323</td>\n",
       "      <td>-0.032981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>спрос</td>\n",
       "      <td>цена</td>\n",
       "      <td>3</td>\n",
       "      <td>должен быть особый спрос а они обязаны</td>\n",
       "      <td>-8.694857</td>\n",
       "      <td>1.759700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462627</td>\n",
       "      <td>-7.467853e-36</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.005002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>спрос</td>\n",
       "      <td>рынок</td>\n",
       "      <td>3</td>\n",
       "      <td>должен быть особый спрос а они обязаны</td>\n",
       "      <td>-8.791276</td>\n",
       "      <td>1.663281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.396855</td>\n",
       "      <td>-7.816035e-36</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>обязывать</td>\n",
       "      <td>должный</td>\n",
       "      <td>3</td>\n",
       "      <td>спрос а они обязаны понимать что несут</td>\n",
       "      <td>-7.060074</td>\n",
       "      <td>4.098417</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434679</td>\n",
       "      <td>2.765546e-27</td>\n",
       "      <td>11.825139</td>\n",
       "      <td>-0.020627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>присяга</td>\n",
       "      <td>решение</td>\n",
       "      <td>3</td>\n",
       "      <td>что приведение к присяге избранного президента...</td>\n",
       "      <td>-8.152354</td>\n",
       "      <td>3.160901</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349902</td>\n",
       "      <td>-2.538559e-32</td>\n",
       "      <td>-1.792054</td>\n",
       "      <td>-0.011637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>присяга</td>\n",
       "      <td>конституция</td>\n",
       "      <td>3</td>\n",
       "      <td>что приведение к присяге избранного президента...</td>\n",
       "      <td>-10.270540</td>\n",
       "      <td>1.042715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347395</td>\n",
       "      <td>-2.538382e-32</td>\n",
       "      <td>-1.791705</td>\n",
       "      <td>0.080414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>четверг</td>\n",
       "      <td>пятница</td>\n",
       "      <td>5</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-10.516444</td>\n",
       "      <td>0.277098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900780</td>\n",
       "      <td>-6.117150e-37</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>0.064990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>четверг</td>\n",
       "      <td>понедельник</td>\n",
       "      <td>5</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-10.606044</td>\n",
       "      <td>0.187498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899482</td>\n",
       "      <td>-7.897369e-37</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.073502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>четверг</td>\n",
       "      <td>суббота</td>\n",
       "      <td>5</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-10.262103</td>\n",
       "      <td>0.531439</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794288</td>\n",
       "      <td>-1.538702e-36</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>0.019752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>четверг</td>\n",
       "      <td>среда</td>\n",
       "      <td>5</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-9.005832</td>\n",
       "      <td>1.787710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750523</td>\n",
       "      <td>-3.925104e-36</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.069399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>четверг</td>\n",
       "      <td>воскресение</td>\n",
       "      <td>5</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-9.769169</td>\n",
       "      <td>1.024373</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732769</td>\n",
       "      <td>-1.924553e-36</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>четверг</td>\n",
       "      <td>вчера</td>\n",
       "      <td>5</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-8.817499</td>\n",
       "      <td>1.976043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691816</td>\n",
       "      <td>2.813672e-36</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>четверг</td>\n",
       "      <td>сегодня</td>\n",
       "      <td>5</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-7.874007</td>\n",
       "      <td>2.919535</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>2.796021e-36</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>парламентарий</td>\n",
       "      <td>депутат</td>\n",
       "      <td>6</td>\n",
       "      <td>мая соответствующее решение поддержали в четве...</td>\n",
       "      <td>-9.544944</td>\n",
       "      <td>3.140118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574272</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>заведение</td>\n",
       "      <td>ресторан</td>\n",
       "      <td>3</td>\n",
       "      <td>выпускников высших учебных заведений получивши...</td>\n",
       "      <td>-9.832919</td>\n",
       "      <td>0.158408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416735</td>\n",
       "      <td>-2.379558e-28</td>\n",
       "      <td>-6.885306</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>мэр</td>\n",
       "      <td>депутат</td>\n",
       "      <td>3</td>\n",
       "      <td>что поговорит с мэром москвы сергеем собяниным</td>\n",
       "      <td>-9.544944</td>\n",
       "      <td>1.092480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374717</td>\n",
       "      <td>-7.097175e-31</td>\n",
       "      <td>-2.707929</td>\n",
       "      <td>0.054354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>планировать</td>\n",
       "      <td>готовый</td>\n",
       "      <td>3</td>\n",
       "      <td>о ситуации с планируемым вывозом мусора из</td>\n",
       "      <td>-8.346391</td>\n",
       "      <td>2.509005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484121</td>\n",
       "      <td>-1.152724e-35</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>медиафорум</td>\n",
       "      <td>конференция</td>\n",
       "      <td>3</td>\n",
       "      <td>заявил президент на медиафоруме онф в сочи</td>\n",
       "      <td>-10.081684</td>\n",
       "      <td>8.985195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391646</td>\n",
       "      <td>-1.706130e-36</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>0.058518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>онф</td>\n",
       "      <td>оппозиция</td>\n",
       "      <td>4</td>\n",
       "      <td>заявил президент на медиафоруме онф в сочи</td>\n",
       "      <td>-10.784902</td>\n",
       "      <td>8.281977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659366</td>\n",
       "      <td>-2.647282e-37</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>поздний</td>\n",
       "      <td>ранний</td>\n",
       "      <td>3</td>\n",
       "      <td>планируется завершить к поздней осени заявил п...</td>\n",
       "      <td>-9.616656</td>\n",
       "      <td>0.397707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570405</td>\n",
       "      <td>7.783308e-36</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.031363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>закрытый</td>\n",
       "      <td>открытый</td>\n",
       "      <td>3</td>\n",
       "      <td>на состоявшемся мая закрытом заседании комитет...</td>\n",
       "      <td>-8.918212</td>\n",
       "      <td>1.249482</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413190</td>\n",
       "      <td>1.270681e-37</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.030772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>присутствовать</td>\n",
       "      <td>участвовать</td>\n",
       "      <td>3</td>\n",
       "      <td>заседании комитета заставить присутствовавшую ...</td>\n",
       "      <td>-9.389289</td>\n",
       "      <td>0.277704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438249</td>\n",
       "      <td>-7.060072e-39</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>премьер-министр</td>\n",
       "      <td>президент</td>\n",
       "      <td>3</td>\n",
       "      <td>своей отставки однако премьер-министр уклонила...</td>\n",
       "      <td>-8.718000</td>\n",
       "      <td>2.800849</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439250</td>\n",
       "      <td>-2.370664e-36</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>премьер-министр</td>\n",
       "      <td>министр</td>\n",
       "      <td>3</td>\n",
       "      <td>своей отставки однако премьер-министр уклонила...</td>\n",
       "      <td>-8.730505</td>\n",
       "      <td>2.788344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432126</td>\n",
       "      <td>-1.086558e-36</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.025244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>премьер-министр</td>\n",
       "      <td>правительство</td>\n",
       "      <td>3</td>\n",
       "      <td>своей отставки однако премьер-министр уклонила...</td>\n",
       "      <td>-8.327638</td>\n",
       "      <td>3.191211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406683</td>\n",
       "      <td>-2.469439e-36</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>кабмин</td>\n",
       "      <td>правительство</td>\n",
       "      <td>3</td>\n",
       "      <td>срок ее руководства кабмином об этом она</td>\n",
       "      <td>-8.327638</td>\n",
       "      <td>8.436655</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696020</td>\n",
       "      <td>-1.274088e-35</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.062934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>виновник</td>\n",
       "      <td>автор</td>\n",
       "      <td>3</td>\n",
       "      <td>о том что виновником возникновения крупнейшего в</td>\n",
       "      <td>-8.483228</td>\n",
       "      <td>2.931580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142253</td>\n",
       "      <td>1.465960e-29</td>\n",
       "      <td>5.187052</td>\n",
       "      <td>0.011974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>виновник</td>\n",
       "      <td>причина</td>\n",
       "      <td>3</td>\n",
       "      <td>о том что виновником возникновения крупнейшего в</td>\n",
       "      <td>-8.326144</td>\n",
       "      <td>3.088664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>3.459020e-30</td>\n",
       "      <td>3.760875</td>\n",
       "      <td>0.032383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>возникновение</td>\n",
       "      <td>рождение</td>\n",
       "      <td>3</td>\n",
       "      <td>том что виновником возникновения крупнейшего в...</td>\n",
       "      <td>-9.462067</td>\n",
       "      <td>1.079056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>3.907926e-38</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>эксперт</td>\n",
       "      <td>специалист</td>\n",
       "      <td>2</td>\n",
       "      <td>по данным экспертов снижение рождаемости наблю...</td>\n",
       "      <td>-9.194675</td>\n",
       "      <td>1.053425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451029</td>\n",
       "      <td>1.521219e-32</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>показатель</td>\n",
       "      <td>знак</td>\n",
       "      <td>3</td>\n",
       "      <td>в м этот показатель достиг рекордного минимума</td>\n",
       "      <td>-9.010198</td>\n",
       "      <td>0.695423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043610</td>\n",
       "      <td>-2.537681e-32</td>\n",
       "      <td>-1.791577</td>\n",
       "      <td>-0.008830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>генетик</td>\n",
       "      <td>биолог</td>\n",
       "      <td>2</td>\n",
       "      <td>международная группа генетиков и археологов из...</td>\n",
       "      <td>-11.948863</td>\n",
       "      <td>0.574104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661766</td>\n",
       "      <td>-1.923851e-37</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.098699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>подъемник</td>\n",
       "      <td>лифт</td>\n",
       "      <td>3</td>\n",
       "      <td>оказались заблокированными на подъемнике когда...</td>\n",
       "      <td>-10.858659</td>\n",
       "      <td>2.268048</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514473</td>\n",
       "      <td>-2.462136e-35</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.003079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>небоскреб</td>\n",
       "      <td>дом</td>\n",
       "      <td>3</td>\n",
       "      <td>в верхней части небоскреба инцидент произошел ...</td>\n",
       "      <td>-7.446301</td>\n",
       "      <td>4.975486</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305170</td>\n",
       "      <td>-3.546052e-35</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.059672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>инцидент</td>\n",
       "      <td>дело</td>\n",
       "      <td>3</td>\n",
       "      <td>верхней части небоскреба инцидент произошел ут...</td>\n",
       "      <td>-6.454828</td>\n",
       "      <td>5.224961</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119077</td>\n",
       "      <td>-9.154800e-37</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.005495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>инцидент</td>\n",
       "      <td>случай</td>\n",
       "      <td>3</td>\n",
       "      <td>верхней части небоскреба инцидент произошел ут...</td>\n",
       "      <td>-7.246549</td>\n",
       "      <td>4.433239</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192839</td>\n",
       "      <td>-1.111452e-37</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.012834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>инцидент</td>\n",
       "      <td>событие</td>\n",
       "      <td>3</td>\n",
       "      <td>верхней части небоскреба инцидент произошел ут...</td>\n",
       "      <td>-8.652756</td>\n",
       "      <td>3.027033</td>\n",
       "      <td>0</td>\n",
       "      <td>0.342534</td>\n",
       "      <td>-4.727746e-37</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>инцидент</td>\n",
       "      <td>факт</td>\n",
       "      <td>3</td>\n",
       "      <td>верхней части небоскреба инцидент произошел ут...</td>\n",
       "      <td>-8.730797</td>\n",
       "      <td>2.948991</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127271</td>\n",
       "      <td>3.704950e-38</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.015339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>уроженец</td>\n",
       "      <td>житель</td>\n",
       "      <td>1</td>\n",
       "      <td>летний уроженец латвии эдвард пургайлис был избит</td>\n",
       "      <td>-9.168002</td>\n",
       "      <td>3.074503</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392782</td>\n",
       "      <td>-7.060379e-38</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>уроженец</td>\n",
       "      <td>сын</td>\n",
       "      <td>1</td>\n",
       "      <td>летний уроженец латвии эдвард пургайлис был избит</td>\n",
       "      <td>-7.944362</td>\n",
       "      <td>4.298143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186387</td>\n",
       "      <td>-1.500305e-37</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.097134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>британский</td>\n",
       "      <td>английский</td>\n",
       "      <td>3</td>\n",
       "      <td>в школе в британском городке бутл агломерации</td>\n",
       "      <td>-9.091582</td>\n",
       "      <td>1.733857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366162</td>\n",
       "      <td>2.013152e-36</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>городок</td>\n",
       "      <td>город</td>\n",
       "      <td>3</td>\n",
       "      <td>школе в британском городке бутл агломерации ме...</td>\n",
       "      <td>-7.357622</td>\n",
       "      <td>2.863768</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407607</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>ресторан</td>\n",
       "      <td>здание</td>\n",
       "      <td>4</td>\n",
       "      <td>поставляющий свой улов в рестораны премиум класса</td>\n",
       "      <td>-9.095919</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231827</td>\n",
       "      <td>6.542238e-36</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>-0.017397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>наезд</td>\n",
       "      <td>приезд</td>\n",
       "      <td>4</td>\n",
       "      <td>водитель продолжил движение после наезда на пе...</td>\n",
       "      <td>-9.900386</td>\n",
       "      <td>2.559843</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063474</td>\n",
       "      <td>3.045834e-32</td>\n",
       "      <td>1.945817</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>маневр</td>\n",
       "      <td>действие</td>\n",
       "      <td>3</td>\n",
       "      <td>во время совершения маневров в гавани военно-м...</td>\n",
       "      <td>-8.051517</td>\n",
       "      <td>2.911565</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283959</td>\n",
       "      <td>3.187227e-36</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>маневр</td>\n",
       "      <td>демонстрация</td>\n",
       "      <td>3</td>\n",
       "      <td>во время совершения маневров в гавани военно-м...</td>\n",
       "      <td>-10.945695</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078477</td>\n",
       "      <td>9.562036e-36</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.029689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>гавань</td>\n",
       "      <td>порт</td>\n",
       "      <td>3</td>\n",
       "      <td>совершения маневров в гавани военно-морской ба...</td>\n",
       "      <td>-10.111560</td>\n",
       "      <td>1.483956</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269368</td>\n",
       "      <td>-2.070629e-36</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>0.061295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>подлодка</td>\n",
       "      <td>корабль</td>\n",
       "      <td>3</td>\n",
       "      <td>норвегии хааконсверн немецкая подлодка задела ...</td>\n",
       "      <td>-8.907045</td>\n",
       "      <td>3.389044</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512603</td>\n",
       "      <td>-1.235580e-38</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.062688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>издание</td>\n",
       "      <td>карта</td>\n",
       "      <td>3</td>\n",
       "      <td>об этом сообщает издание в результате происшес...</td>\n",
       "      <td>-9.180131</td>\n",
       "      <td>0.495254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093112</td>\n",
       "      <td>7.476185e-34</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-0.002497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>издание</td>\n",
       "      <td>книга</td>\n",
       "      <td>3</td>\n",
       "      <td>об этом сообщает издание в результате происшес...</td>\n",
       "      <td>-7.785658</td>\n",
       "      <td>1.889726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130477</td>\n",
       "      <td>-7.875916e-34</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.021956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>издание</td>\n",
       "      <td>труд</td>\n",
       "      <td>3</td>\n",
       "      <td>об этом сообщает издание в результате происшес...</td>\n",
       "      <td>-8.134343</td>\n",
       "      <td>1.541041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>7.225282e-34</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.015115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>происшествие</td>\n",
       "      <td>дело</td>\n",
       "      <td>3</td>\n",
       "      <td>издание в результате происшествия никто не пос...</td>\n",
       "      <td>-6.454828</td>\n",
       "      <td>3.915039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084620</td>\n",
       "      <td>1.230572e-29</td>\n",
       "      <td>1.945864</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>происшествие</td>\n",
       "      <td>случай</td>\n",
       "      <td>3</td>\n",
       "      <td>издание в результате происшествия никто не пос...</td>\n",
       "      <td>-7.246549</td>\n",
       "      <td>3.123318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101789</td>\n",
       "      <td>9.742390e-30</td>\n",
       "      <td>1.749187</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>происшествие</td>\n",
       "      <td>событие</td>\n",
       "      <td>3</td>\n",
       "      <td>издание в результате происшествия никто не пос...</td>\n",
       "      <td>-8.652756</td>\n",
       "      <td>1.717112</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209963</td>\n",
       "      <td>1.538288e-30</td>\n",
       "      <td>0.559613</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>происшествие</td>\n",
       "      <td>сцена</td>\n",
       "      <td>3</td>\n",
       "      <td>издание в результате происшествия никто не пос...</td>\n",
       "      <td>-8.787904</td>\n",
       "      <td>1.581963</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>-1.538296e-30</td>\n",
       "      <td>-1.386293</td>\n",
       "      <td>-0.010324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>происшествие</td>\n",
       "      <td>факт</td>\n",
       "      <td>3</td>\n",
       "      <td>издание в результате происшествия никто не пос...</td>\n",
       "      <td>-8.730797</td>\n",
       "      <td>1.639070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080331</td>\n",
       "      <td>-1.538296e-30</td>\n",
       "      <td>-1.386292</td>\n",
       "      <td>0.082857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            исходное         замена индекс  \\\n",
       "0              мэрия  администрация      0   \n",
       "1              опрос   исследование      3   \n",
       "2          интерфакс           тасс      3   \n",
       "3                мэр        депутат      3   \n",
       "4              опрос   исследование      3   \n",
       "5              спрос           цена      3   \n",
       "6              спрос          рынок      3   \n",
       "7          обязывать        должный      3   \n",
       "8            присяга        решение      3   \n",
       "9            присяга    конституция      3   \n",
       "10           четверг        пятница      5   \n",
       "11           четверг    понедельник      5   \n",
       "12           четверг        суббота      5   \n",
       "13           четверг          среда      5   \n",
       "14           четверг    воскресение      5   \n",
       "15           четверг          вчера      5   \n",
       "16           четверг        сегодня      5   \n",
       "17     парламентарий        депутат      6   \n",
       "18         заведение       ресторан      3   \n",
       "19               мэр        депутат      3   \n",
       "20       планировать        готовый      3   \n",
       "21        медиафорум    конференция      3   \n",
       "22               онф      оппозиция      4   \n",
       "23           поздний         ранний      3   \n",
       "24          закрытый       открытый      3   \n",
       "25    присутствовать    участвовать      3   \n",
       "26   премьер-министр      президент      3   \n",
       "27   премьер-министр        министр      3   \n",
       "28   премьер-министр  правительство      3   \n",
       "29            кабмин  правительство      3   \n",
       "..               ...            ...    ...   \n",
       "703         виновник          автор      3   \n",
       "704         виновник        причина      3   \n",
       "705    возникновение       рождение      3   \n",
       "706          эксперт     специалист      2   \n",
       "707       показатель           знак      3   \n",
       "708          генетик         биолог      2   \n",
       "709        подъемник           лифт      3   \n",
       "710        небоскреб            дом      3   \n",
       "711         инцидент           дело      3   \n",
       "712         инцидент         случай      3   \n",
       "713         инцидент        событие      3   \n",
       "714         инцидент           факт      3   \n",
       "715         уроженец         житель      1   \n",
       "716         уроженец            сын      1   \n",
       "717       британский     английский      3   \n",
       "718          городок          город      3   \n",
       "719         ресторан         здание      4   \n",
       "720            наезд         приезд      4   \n",
       "721           маневр       действие      3   \n",
       "722           маневр   демонстрация      3   \n",
       "723           гавань           порт      3   \n",
       "724         подлодка        корабль      3   \n",
       "725          издание          карта      3   \n",
       "726          издание          книга      3   \n",
       "727          издание           труд      3   \n",
       "728     происшествие           дело      3   \n",
       "729     происшествие         случай      3   \n",
       "730     происшествие        событие      3   \n",
       "731     происшествие          сцена      3   \n",
       "732     происшествие           факт      3   \n",
       "\n",
       "                                              контекст  сложность  \\\n",
       "0    мэрия екатеринбурга готова провести опрос насе...  -9.758051   \n",
       "1    екатеринбурга готова провести опрос населения ...  -8.779933   \n",
       "2    сквера сообщает агентство интерфакс со ссылкой на -12.146207   \n",
       "3    ссылкой на заместителя мэра города екатерину к...  -9.544944   \n",
       "4    предложением о проведении опроса местных жител...  -8.779933   \n",
       "5               должен быть особый спрос а они обязаны  -8.694857   \n",
       "6               должен быть особый спрос а они обязаны  -8.791276   \n",
       "7               спрос а они обязаны понимать что несут  -7.060074   \n",
       "8    что приведение к присяге избранного президента...  -8.152354   \n",
       "9    что приведение к присяге избранного президента... -10.270540   \n",
       "10   мая соответствующее решение поддержали в четве... -10.516444   \n",
       "11   мая соответствующее решение поддержали в четве... -10.606044   \n",
       "12   мая соответствующее решение поддержали в четве... -10.262103   \n",
       "13   мая соответствующее решение поддержали в четве...  -9.005832   \n",
       "14   мая соответствующее решение поддержали в четве...  -9.769169   \n",
       "15   мая соответствующее решение поддержали в четве...  -8.817499   \n",
       "16   мая соответствующее решение поддержали в четве...  -7.874007   \n",
       "17   мая соответствующее решение поддержали в четве...  -9.544944   \n",
       "18   выпускников высших учебных заведений получивши...  -9.832919   \n",
       "19      что поговорит с мэром москвы сергеем собяниным  -9.544944   \n",
       "20          о ситуации с планируемым вывозом мусора из  -8.346391   \n",
       "21          заявил президент на медиафоруме онф в сочи -10.081684   \n",
       "22          заявил президент на медиафоруме онф в сочи -10.784902   \n",
       "23   планируется завершить к поздней осени заявил п...  -9.616656   \n",
       "24   на состоявшемся мая закрытом заседании комитет...  -8.918212   \n",
       "25   заседании комитета заставить присутствовавшую ...  -9.389289   \n",
       "26   своей отставки однако премьер-министр уклонила...  -8.718000   \n",
       "27   своей отставки однако премьер-министр уклонила...  -8.730505   \n",
       "28   своей отставки однако премьер-министр уклонила...  -8.327638   \n",
       "29            срок ее руководства кабмином об этом она  -8.327638   \n",
       "..                                                 ...        ...   \n",
       "703   о том что виновником возникновения крупнейшего в  -8.483228   \n",
       "704   о том что виновником возникновения крупнейшего в  -8.326144   \n",
       "705  том что виновником возникновения крупнейшего в...  -9.462067   \n",
       "706  по данным экспертов снижение рождаемости наблю...  -9.194675   \n",
       "707     в м этот показатель достиг рекордного минимума  -9.010198   \n",
       "708  международная группа генетиков и археологов из... -11.948863   \n",
       "709  оказались заблокированными на подъемнике когда... -10.858659   \n",
       "710  в верхней части небоскреба инцидент произошел ...  -7.446301   \n",
       "711  верхней части небоскреба инцидент произошел ут...  -6.454828   \n",
       "712  верхней части небоскреба инцидент произошел ут...  -7.246549   \n",
       "713  верхней части небоскреба инцидент произошел ут...  -8.652756   \n",
       "714  верхней части небоскреба инцидент произошел ут...  -8.730797   \n",
       "715  летний уроженец латвии эдвард пургайлис был избит  -9.168002   \n",
       "716  летний уроженец латвии эдвард пургайлис был избит  -7.944362   \n",
       "717      в школе в британском городке бутл агломерации  -9.091582   \n",
       "718  школе в британском городке бутл агломерации ме...  -7.357622   \n",
       "719  поставляющий свой улов в рестораны премиум класса  -9.095919   \n",
       "720  водитель продолжил движение после наезда на пе...  -9.900386   \n",
       "721  во время совершения маневров в гавани военно-м...  -8.051517   \n",
       "722  во время совершения маневров в гавани военно-м... -10.945695   \n",
       "723  совершения маневров в гавани военно-морской ба... -10.111560   \n",
       "724  норвегии хааконсверн немецкая подлодка задела ...  -8.907045   \n",
       "725  об этом сообщает издание в результате происшес...  -9.180131   \n",
       "726  об этом сообщает издание в результате происшес...  -7.785658   \n",
       "727  об этом сообщает издание в результате происшес...  -8.134343   \n",
       "728  издание в результате происшествия никто не пос...  -6.454828   \n",
       "729  издание в результате происшествия никто не пос...  -7.246549   \n",
       "730  издание в результате происшествия никто не пос...  -8.652756   \n",
       "731  издание в результате происшествия никто не пос...  -8.787904   \n",
       "732  издание в результате происшествия никто не пос...  -8.730797   \n",
       "\n",
       "     разница_сложности словарность  близость  разница_вероятности  \\\n",
       "0             2.118905           0  0.488974        -1.765001e-38   \n",
       "1             2.464501           0  0.512625        -7.517182e-37   \n",
       "2             1.029027           0  0.688722         2.041090e-35   \n",
       "3             1.092480           0  0.374717         6.614308e-37   \n",
       "4             2.464501           0  0.512625        -2.282582e-31   \n",
       "5             1.759700           0  0.462627        -7.467853e-36   \n",
       "6             1.663281           0  0.396855        -7.816035e-36   \n",
       "7             4.098417           0  0.434679         2.765546e-27   \n",
       "8             3.160901           0  0.349902        -2.538559e-32   \n",
       "9             1.042715           0  0.347395        -2.538382e-32   \n",
       "10            0.277098           0  0.900780        -6.117150e-37   \n",
       "11            0.187498           0  0.899482        -7.897369e-37   \n",
       "12            0.531439           0  0.794288        -1.538702e-36   \n",
       "13            1.787710           0  0.750523        -3.925104e-36   \n",
       "14            1.024373           0  0.732769        -1.924553e-36   \n",
       "15            1.976043           0  0.691816         2.813672e-36   \n",
       "16            2.919535           0  0.642792         2.796021e-36   \n",
       "17            3.140118           0  0.574272         0.000000e+00   \n",
       "18            0.158408           0  0.416735        -2.379558e-28   \n",
       "19            1.092480           0  0.374717        -7.097175e-31   \n",
       "20            2.509005           0  0.484121        -1.152724e-35   \n",
       "21            8.985195           0  0.391646        -1.706130e-36   \n",
       "22            8.281977           0  0.659366        -2.647282e-37   \n",
       "23            0.397707           0  0.570405         7.783308e-36   \n",
       "24            1.249482           0  0.413190         1.270681e-37   \n",
       "25            0.277704           0  0.438249        -7.060072e-39   \n",
       "26            2.800849           0  0.439250        -2.370664e-36   \n",
       "27            2.788344           0  0.432126        -1.086558e-36   \n",
       "28            3.191211           0  0.406683        -2.469439e-36   \n",
       "29            8.436655           0  0.696020        -1.274088e-35   \n",
       "..                 ...         ...       ...                  ...   \n",
       "703           2.931580           0  0.142253         1.465960e-29   \n",
       "704           3.088664           0  0.538800         3.459020e-30   \n",
       "705           1.079056           0  0.057538         3.907926e-38   \n",
       "706           1.053425           0  0.451029         1.521219e-32   \n",
       "707           0.695423           0  0.043610        -2.537681e-32   \n",
       "708           0.574104           0  0.661766        -1.923851e-37   \n",
       "709           2.268048           0  0.514473        -2.462136e-35   \n",
       "710           4.975486           0  0.305170        -3.546052e-35   \n",
       "711           5.224961           0  0.119077        -9.154800e-37   \n",
       "712           4.433239           0  0.192839        -1.111452e-37   \n",
       "713           3.027033           0  0.342534        -4.727746e-37   \n",
       "714           2.948991           0  0.127271         3.704950e-38   \n",
       "715           3.074503           0  0.392782        -7.060379e-38   \n",
       "716           4.298143           0  0.186387        -1.500305e-37   \n",
       "717           1.733857           0  0.366162         2.013152e-36   \n",
       "718           2.863768           0  0.407607         0.000000e+00   \n",
       "719           0.737000           0  0.231827         6.542238e-36   \n",
       "720           2.559843           0  0.063474         3.045834e-32   \n",
       "721           2.911565           0  0.283959         3.187227e-36   \n",
       "722           0.017387           0  0.078477         9.562036e-36   \n",
       "723           1.483956           0  0.269368        -2.070629e-36   \n",
       "724           3.389044           0  0.512603        -1.235580e-38   \n",
       "725           0.495254           0  0.093112         7.476185e-34   \n",
       "726           1.889726           0  0.130477        -7.875916e-34   \n",
       "727           1.541041           0  0.032505         7.225282e-34   \n",
       "728           3.915039           0  0.084620         1.230572e-29   \n",
       "729           3.123318           0  0.101789         9.742390e-30   \n",
       "730           1.717112           0  0.209963         1.538288e-30   \n",
       "731           1.581963           0  0.024374        -1.538296e-30   \n",
       "732           1.639070           0  0.080331        -1.538296e-30   \n",
       "\n",
       "     разница_лог_вероятности  контекстуальность класс  \n",
       "0                  -0.000003           0.019178     0  \n",
       "1                  -0.000148           0.015821     0  \n",
       "2                   0.000016           0.060943     0  \n",
       "3                   0.000130           0.028308     0  \n",
       "4                  -1.386323          -0.032981     0  \n",
       "5                  -0.000067          -0.005002     0  \n",
       "6                  -0.000070          -0.002635     0  \n",
       "7                  11.825139          -0.020627     0  \n",
       "8                  -1.792054          -0.011637     0  \n",
       "9                  -1.791705           0.080414     0  \n",
       "10                 -0.000121           0.064990     0  \n",
       "11                 -0.000156           0.073502     0  \n",
       "12                 -0.000303           0.019752     0  \n",
       "13                 -0.000774           0.069399     0  \n",
       "14                 -0.000379           0.013924     0  \n",
       "15                  0.000554           0.047522     0  \n",
       "16                  0.000551           0.071397     0  \n",
       "17                  0.000000           0.077450     0  \n",
       "18                 -6.885306           0.004390     0  \n",
       "19                 -2.707929           0.054354     0  \n",
       "20                 -0.000084           0.016573     0  \n",
       "21                 -0.000336           0.058518     0  \n",
       "22                 -0.000052           0.051281     0  \n",
       "23                  0.000139           0.031363     0  \n",
       "24                  0.000025           0.030772     0  \n",
       "25                 -0.000001           0.006594     0  \n",
       "26                 -0.000008           0.034357     0  \n",
       "27                 -0.000004           0.025244     0  \n",
       "28                 -0.000009           0.044800     0  \n",
       "29                 -0.000033           0.062934     0  \n",
       "..                       ...                ...   ...  \n",
       "703                 5.187052           0.011974     0  \n",
       "704                 3.760875           0.032383     0  \n",
       "705                 0.000001          -0.008437     0  \n",
       "706                 0.223144           0.014632     0  \n",
       "707                -1.791577          -0.008830     0  \n",
       "708                -0.000038           0.098699     0  \n",
       "709                -0.000065          -0.003079     0  \n",
       "710                -0.000016           0.059672     0  \n",
       "711                -0.000180          -0.005495     0  \n",
       "712                -0.000022          -0.012834     0  \n",
       "713                -0.000093           0.006443     0  \n",
       "714                 0.000007           0.015339     0  \n",
       "715                -0.000014           0.017751     0  \n",
       "716                -0.000030           0.097134     0  \n",
       "717                 0.000080           0.021884     0  \n",
       "718                 0.000000           0.058679     0  \n",
       "719                 0.001290          -0.017397     0  \n",
       "720                 1.945817           0.014346     0  \n",
       "721                 0.000014          -0.000923     0  \n",
       "722                 0.000041           0.029689     0  \n",
       "723                -0.000408           0.061295     0  \n",
       "724                -0.000002           0.062688     0  \n",
       "725                 0.000104          -0.002497     0  \n",
       "726                -0.000109          -0.021956     0  \n",
       "727                 0.000100          -0.015115     0  \n",
       "728                 1.945864           0.004393     0  \n",
       "729                 1.749187           0.039661     0  \n",
       "730                 0.559613          -0.003189     0  \n",
       "731                -1.386293          -0.010324     0  \n",
       "732                -1.386292           0.082857     0  \n",
       "\n",
       "[733 rows x 12 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'class_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-649bc901717e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclass_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class_df.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1403\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1575\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m   1576\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m   1578\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'class_df.csv'"
     ]
    }
   ],
   "source": [
    "class_df.to_csv('class_df.csv',sep='\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Штука. Пока не трогать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "изъяли 3 : ['бракованный', 'белорусский', 'лекарство', 'изымать', 'из', 'обращение', 'лекарственный']\n",
      "[('бракованный', 'белорусский', 'лекарство'), ('белорусский', 'лекарство', 'изымать'), ('лекарство', 'изымать', 'из'), ('изымать', 'из', 'обращение'), ('из', 'обращение', 'лекарственный')]\n",
      "\t бракованный белорусский лекарство / бракованный белорусский : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t белорусский лекарство изымать / белорусский лекарство : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t лекарство изымать из / лекарство изымать : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t изымать из обращение / изымать из : 26 / 450 ( 27 / 2876993 ) = 9.38479864219343e-06\n",
      "\t из обращение лекарственный / из обращение : 0 / 158 ( 1 / 2876701 ) = 3.4762041658135483e-07\n",
      "\n",
      "Вероятность слова _изъяли_ в контексте ['бракованный', 'белорусский', 'лекарство', 'изымать', 'из', 'обращение', 'лекарственный'] = -71.0648734045552, близость к контексту = 0.06318795363628794\n",
      "\n",
      "\t бракованный белорусский лекарство / бракованный белорусский : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t белорусский лекарство брать / белорусский лекарство : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t лекарство брать из / лекарство брать : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t брать из обращение / брать из : 0 / 315 ( 1 / 2876858 ) = 3.476014457439331e-07\n",
      "\t из обращение лекарственный / из обращение : 0 / 158 ( 1 / 2876701 ) = 3.4762041658135483e-07\n",
      "\n",
      "Вероятность замены _брать_ в контексте ['бракованный', 'белорусский', 'лекарство', 'брать', 'из', 'обращение', 'лекарственный'] = -74.36066334546535, разница = 3.2957899409101543, используем? - НЕТ\n",
      "Близость к контексту = 0.006395086993213012, разница с исходным = 0.05679286664307493\n",
      "\n",
      "пациентам 3 : ['использоваться', 'для', 'инъекция', 'пациент', 'и', 'быть', 'выводить']\n",
      "[('использоваться', 'для', 'инъекция'), ('для', 'инъекция', 'пациент'), ('инъекция', 'пациент', 'и'), ('пациент', 'и', 'быть'), ('и', 'быть', 'выводить')]\n",
      "\t использоваться для инъекция / использоваться для : 0 / 1017 ( 1 / 2877560 ) = 3.475166460473457e-07\n",
      "\t для инъекция пациент / для инъекция : 0 / 110 ( 1 / 2876653 ) = 3.4762621699593243e-07\n",
      "\t инъекция пациент и / инъекция пациент : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t пациент и быть / пациент и : 0 / 128 ( 1 / 2876671 ) = 3.4762404181778176e-07\n",
      "\t и быть выводить / и быть : 8 / 3 ( 9 / 2876546 ) = 3.128752330051388e-06\n",
      "\n",
      "Вероятность слова _пациентам_ в контексте ['использоваться', 'для', 'инъекция', 'пациент', 'и', 'быть', 'выводить'] = -72.16371160844305, близость к контексту = 0.018838279596461813\n",
      "\n",
      "\t использоваться для инъекция / использоваться для : 0 / 1017 ( 1 / 2877560 ) = 3.475166460473457e-07\n",
      "\t для инъекция больной / для инъекция : 0 / 110 ( 1 / 2876653 ) = 3.4762621699593243e-07\n",
      "\t инъекция больной и / инъекция больной : 0 / 0 ( 1 / 2876543 ) = 3.476395103427969e-07\n",
      "\t больной и быть / больной и : 0 / 505 ( 1 / 2877048 ) = 3.4757849017465123e-07\n",
      "\t и быть выводить / и быть : 8 / 3 ( 9 / 2876546 ) = 3.128752330051388e-06\n",
      "\n",
      "Вероятность замены _больной_ в контексте ['использоваться', 'для', 'инъекция', 'больной', 'и', 'быть', 'выводить'] = -72.16384265411995, разница = 0.00013104567689481428, используем? - НЕТ\n",
      "Близость к контексту = 0.03575225068896881, разница с исходным = -0.016913971092507\n",
      "\n",
      "выведены 3 : ['пациент', 'и', 'быть', 'выводить', 'из', 'обращение', 'об']\n",
      "[('пациент', 'и', 'быть'), ('и', 'быть', 'выводить'), ('быть', 'выводить', 'из'), ('выводить', 'из', 'обращение'), ('из', 'обращение', 'об')]\n",
      "\t пациент и быть / пациент и : 0 / 128 ( 1 / 2876671 ) = 3.4762404181778176e-07\n",
      "\t и быть выводить / и быть : 8 / 3 ( 9 / 2876546 ) = 3.128752330051388e-06\n",
      "\t быть выводить из / быть выводить : 176 / 560 ( 177 / 2877103 ) = 6.152021669019149e-05\n",
      "\t выводить из обращение / выводить из : 0 / 2088 ( 1 / 2878631 ) = 3.473873518349521e-07\n",
      "\t из обращение об / из обращение : 0 / 158 ( 1 / 2876701 ) = 3.4762041658135483e-07\n",
      "\n",
      "Вероятность слова _выведены_ в контексте ['пациент', 'и', 'быть', 'выводить', 'из', 'обращение', 'об'] = -66.98814534204917, близость к контексту = -0.031232112809915818\n",
      "\n",
      "\t пациент и быть / пациент и : 0 / 128 ( 1 / 2876671 ) = 3.4762404181778176e-07\n",
      "\t и быть открывать / и быть : 24 / 3 ( 25 / 2876546 ) = 8.690978694587188e-06\n",
      "\t быть открывать из / быть открывать : 0 / 13 ( 1 / 2876556 ) = 3.4763793925791814e-07\n",
      "\t открывать из обращение / открывать из : 0 / 12 ( 1 / 2876555 ) = 3.47638060110097e-07\n",
      "\t из обращение об / из обращение : 0 / 158 ( 1 / 2876701 ) = 3.4762041658135483e-07\n",
      "\n",
      "Вероятность замены _открывать_ в контексте ['пациент', 'и', 'быть', 'открывать', 'из', 'обращение', 'об'] = -71.14173225090096, разница = 4.153586908851793, используем? - НЕТ\n",
      "Близость к контексту = -0.020023252691917192, разница с исходным = -0.011208860117998626\n",
      "\n",
      "осложнениях 3 : ['связь', 'с', 'этот', 'осложнение', 'у', 'пациент', 'в']\n",
      "[('связь', 'с', 'этот'), ('с', 'этот', 'осложнение'), ('этот', 'осложнение', 'у'), ('осложнение', 'у', 'пациент'), ('у', 'пациент', 'в')]\n",
      "\t связь с этот / связь с : 196 / 4 ( 197 / 2876547 ) = 6.848488830531885e-05\n",
      "\t с этот осложнение / с этот : 0 / 10 ( 1 / 2876553 ) = 3.476383018147067e-07\n",
      "\t этот осложнение у / этот осложнение : 0 / 9 ( 1 / 2876552 ) = 3.476384226671376e-07\n",
      "\t осложнение у пациент / осложнение у : 0 / 4 ( 1 / 2876547 ) = 3.476390269305525e-07\n",
      "\t у пациент в / у пациент : 3 / 203 ( 4 / 2876746 ) = 1.3904599154739416e-06\n",
      "\n",
      "Вероятность слова _осложнениях_ в контексте ['связь', 'с', 'этот', 'осложнение', 'у', 'пациент', 'в'] = -67.69108078420743, близость к контексту = 0.051135679217402336\n",
      "\n",
      "\t связь с этот / связь с : 196 / 4 ( 197 / 2876547 ) = 6.848488830531885e-05\n",
      "\t с этот проблема / с этот : 131 / 10 ( 132 / 2876553 ) = 4.588825583954128e-05\n",
      "\t этот проблема у / этот проблема : 4 / 3244 ( 5 / 2879787 ) = 1.7362395204923142e-06\n",
      "\t проблема у пациент / проблема у : 0 / 4 ( 1 / 2876547 ) = 3.476390269305525e-07\n",
      "\t у пациент в / у пациент : 3 / 203 ( 4 / 2876746 ) = 1.3904599154739416e-06\n",
      "\n",
      "Вероятность замены _проблема_ в контексте ['связь', 'с', 'этот', 'проблема', 'у', 'пациент', 'в'] = -61.199964927583835, разница = -6.491115856623594, используем? - ДА\n",
      "Близость к контексту = 0.022344491239161508, разница с исходным = 0.028791187978240828\n",
      "\n",
      "\t связь с этот / связь с : 196 / 4 ( 197 / 2876547 ) = 6.848488830531885e-05\n",
      "\t с этот задача / с этот : 171 / 10 ( 172 / 2876553 ) = 5.979378791212955e-05\n",
      "\t этот задача у / этот задача : 0 / 2423 ( 1 / 2878966 ) = 3.4734692941840926e-07\n",
      "\t задача у пациент / задача у : 0 / 88 ( 1 / 2876631 ) = 3.4762887558397304e-07\n",
      "\t у пациент в / у пациент : 3 / 203 ( 4 / 2876746 ) = 1.3904599154739416e-06\n",
      "\n",
      "Вероятность замены _задача_ в контексте ['связь', 'с', 'этот', 'задача', 'у', 'пациент', 'в'] = -62.54445435586746, разница = -5.146626428339971, используем? - ДА\n",
      "Близость к контексту = -0.0017856899107119469, разница с исходным = 0.05292136912811428\n",
      "\n",
      "Лучшее значение вероятности: проблема\n",
      "\n",
      "пациентов 3 : ['этот', 'осложнение', 'у', 'пациент', 'в', 'министерство', 'не']\n",
      "[('этот', 'осложнение', 'у'), ('осложнение', 'у', 'пациент'), ('у', 'пациент', 'в'), ('пациент', 'в', 'министерство'), ('в', 'министерство', 'не')]\n",
      "\t этот осложнение у / этот осложнение : 0 / 9 ( 1 / 2876552 ) = 3.476384226671376e-07\n",
      "\t осложнение у пациент / осложнение у : 0 / 4 ( 1 / 2876547 ) = 3.476390269305525e-07\n",
      "\t у пациент в / у пациент : 3 / 203 ( 4 / 2876746 ) = 1.3904599154739416e-06\n",
      "\t пациент в министерство / пациент в : 0 / 13 ( 1 / 2876556 ) = 3.4763793925791814e-07\n",
      "\t в министерство не / в министерство : 8 / 1920 ( 9 / 2878463 ) = 3.1266686422580385e-06\n",
      "\n",
      "Вероятность слова _пациентов_ в контексте ['этот', 'осложнение', 'у', 'пациент', 'в', 'министерство', 'не'] = -70.77772683316874, близость к контексту = 0.035363689602233184\n",
      "\n",
      "\t этот осложнение у / этот осложнение : 0 / 9 ( 1 / 2876552 ) = 3.476384226671376e-07\n",
      "\t осложнение у больной / осложнение у : 0 / 4 ( 1 / 2876547 ) = 3.476390269305525e-07\n",
      "\t у больной в / у больной : 5 / 1124 ( 6 / 2877667 ) = 2.085022346226996e-06\n",
      "\t больной в министерство / больной в : 0 / 4 ( 1 / 2876547 ) = 3.476390269305525e-07\n",
      "\t в министерство не / в министерство : 8 / 1920 ( 9 / 2878463 ) = 3.1266686422580385e-06\n",
      "\n",
      "Вероятность замены _больной_ в контексте ['этот', 'осложнение', 'у', 'больной', 'в', 'министерство', 'не'] = -70.3725786984716, разница = -0.40514813469714284, используем? - ДА\n",
      "Близость к контексту = 0.034535737622063294, разница с исходным = 0.0008279519801698901\n",
      "\n",
      "Лучшее значение вероятности: больной\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in complex_words:\n",
    "    if isinstance(token, Complex_word):\n",
    "        if token.easier: \n",
    "            # окна контекста строим для тех сложных слов, для которых есть варианты замен, которые проще, чем слово\n",
    "            token.make_window(complex_words, window = 5)\n",
    "            \n",
    "            context_lem = [c.lexem for c in token.context]\n",
    "            \n",
    "            # определение, насколько слово близко с другими словами из контекста\n",
    "            closeness = np.mean([token.cos_sim(w) for w in token.context if w.lexem!=token.lexem])\n",
    "            \n",
    "            print(token.text, token.place, ':', context_lem)\n",
    "            \n",
    "            # генерация n-грамм\n",
    "            text_3grams = [n for n in ngrams(context_lem, 3)]\n",
    "            \n",
    "            print(text_3grams)\n",
    "            \n",
    "            p_context = context_prob(text_3grams, use_log=True)\n",
    "                \n",
    "            print('\\nВероятность слова _{0}_ в контексте {1} = {2}, близость к контексту = {3}\\n'.format(token.text, context_lem, p_context,closeness))\n",
    "            \n",
    "            best_fitness = -1000\n",
    "            best_sub = None\n",
    "            \n",
    "            for sub in token.easier:\n",
    "                \n",
    "                # контекст с новым словом\n",
    "                sub_context = token.context[:token.place]+[sub]+token.context[token.place+1:]\n",
    "                \n",
    "                # определение, насколько слово близко с другими словами из контекста\n",
    "                sub.closeness = np.mean([sub.cos_sim(w) for w in sub_context if w.lexem!=sub.lexem])\n",
    "            \n",
    "                sub_context_lem = [t.lexem for t in sub_context]\n",
    "                \n",
    "                sub_3grams = [n for n in ngrams(sub_context_lem, 3)]\n",
    "                \n",
    "                p_changed_context = context_prob(sub_3grams, use_log=True)\n",
    "                \n",
    "                fit='НЕТ'\n",
    "                if p_changed_context>p_context:\n",
    "                    fit='ДА'\n",
    "                    sub.fitness = p_changed_context\n",
    "                    if sub.fitness > best_fitness:\n",
    "                        best_fitness = sub.fitness\n",
    "                        best_sub = sub\n",
    "                    elif sub.fitness == best_fitness:\n",
    "                        if best_sub.complexity < sub.complexity:\n",
    "                            best_fitness = sub.fitness\n",
    "                            best_sub = sub\n",
    "                        \n",
    "                print('\\nВероятность замены _{0}_ в контексте {1} = {2}, разница = {3}, используем? - {4}'.format(sub.text, sub_context_lem, p_changed_context, p_context-p_changed_context, fit))\n",
    "                print('Близость к контексту = {0}, разница с исходным = {1}\\n'.format(sub.closeness, closeness-sub.closeness))\n",
    "            if best_sub:\n",
    "                print('Лучшее значение вероятности: {0}\\n'.format(best_sub.text))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поправить вычисление вероятности - в знаменателе число уникальных нграмм, а не униграмм, ну и переписать с условием n>/=1\n",
    "изменить вычисление вероятности для логарифма\n",
    "Написать перплексию для получившейся модели - хз как????  \n",
    "поправить нахождение best_sub - если их больше 1, надо как-то это обрабатывать  \n",
    "прогнать статистическую модель на текстах и сформировать таким образом корпус положительных замен, которые потом можно подредачить ручками   \n",
    "заодно при редактировании ручками можно создать еще один файл, в котором редачить, а потом сравнить с первым, чтобы посчитать точность и проч  \n",
    "потом все-таки посчитать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(docs):\n",
    "    docs = np.asarray(docs)\n",
    "    out_of_dict = []\n",
    "   \n",
    "    tmp_sum_docs = 0.0\n",
    "    N = 0.0\n",
    "    for doc in log_progress(docs):\n",
    "        tmp_sum_words = 0.0\n",
    "        for word in log_progress(words):\n",
    "            freq = frequencies.get(word, TOL)\n",
    "            freq_empirical = frequencies_empirical.get(word, 0.0)\n",
    "            N += freq_empirical\n",
    "            if freq == TOL:\n",
    "                out_of_dict.append(word)\n",
    "            tmp_sum_words += freq_empirical * np.log(freq)\n",
    "        tmp_sum_docs += tmp_sum_words\n",
    "       \n",
    "    return np.exp(-tmp_sum_docs / N), out_of_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
